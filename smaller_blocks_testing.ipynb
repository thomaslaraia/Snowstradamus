{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9345fad3",
   "metadata": {},
   "source": [
    "# Smaller Block Computing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47093af5-5637-4b4e-b375-8b0c1d4ca545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to open ATL03 file for file 9's beam 1.\n",
      "Failed to open ATL03 file for file 9's beam 2.\n",
      "Beam 6, box 179 in file 9 has insufficient data.\n",
      "Empty DataFrame\n",
      "Columns: [camera, date, pvpg, y-int1, y-int2, y-int3, y-int4, y-int5, y-int6, longitude, latitude, meanEg1, meanEg3, meanEg5, meanEg2, meanEg4, meanEg6, meanEv1, meanEv3, meanEv5, meanEv2, meanEv4, meanEv6, msw1, msw2, msw3, msw4, msw5, msw6, night1, night2, night3, night4, night5, night6, asr1, asr2, asr3, asr4, asr5, asr6, data_quantity]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 42 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from scripts.FSC_dataframe_phoreal import *\n",
    "from scripts.parallel_blocked import *\n",
    "\n",
    "# from scripts.parallel_phoreal import *\n",
    "# from scripts.parallel_phoreal import *\n",
    "# from scripts.FSC_dataframe import *\n",
    "# from scripts.parallel_blocked import *\n",
    "\n",
    "# dirpath = '../data_store/data/sodankyla_full/'\n",
    "dirpath = '../data/sodankyla_full/'\n",
    "\n",
    "all_ATL03, all_ATL08 = track_pairs(dirpath)\n",
    "N = len(all_ATL03)\n",
    "\n",
    "coords = (26.634154, 67.361833)\n",
    "\n",
    "for i in range(9,10):\n",
    "    data = pvpg_parallel(dirpath, all_ATL03[i], all_ATL08[i], coords=coords, width=.1,height=.1,\\\n",
    "                         graph_detail=0, loss='linear',file_index=i, keep_flagged=1, opsys='bad',f_scale=.1, altitude=185)#, small_box=0.01)\n",
    "    print(data)\n",
    "    # print(flatten_structure(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c279d75d-fa8a-4f80-853d-4fa9181ef5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.parallel_phoreal import *\n",
    "\n",
    "def flatten_structure(structure):\n",
    "    flat_list = []\n",
    "    if isinstance(structure, (list, tuple, np.ndarray)):\n",
    "        for item in structure:\n",
    "            flat_list.extend(flatten_structure(item))\n",
    "    else:\n",
    "        flat_list.append(structure)\n",
    "    return flat_list\n",
    "\n",
    "def datetime_to_date(datetime_obj):\n",
    "    return datetime_obj.strftime('%d/%m/%Y')\n",
    "\n",
    "def pvpg_parallel(atl03path, atl08path, coords, width=.1, height=.1, f_scale = .1, loss = 'arctan', init = -.6,\\\n",
    "                  lb = -np.inf, ub = 0,file_index = None, model = parallel_model, res = parallel_residuals,\\\n",
    "                  odr = parallel_odr, zeros=None,beam = None, y_init = np.max, graph_detail = 0, keep_flagged=True,\\\n",
    "                  opsys='bad', altitude=None,alt_thresh=200, threshold = 2, small_box = 0.01):\n",
    "    \"\"\"\n",
    "    Parallel regression of all tracks on a given overpass.\n",
    "\n",
    "    atl03path - Path/to/ATL03/file\n",
    "    atl08path - Path/to/matching/ATL08/file\n",
    "    f_scale - Parameter in least_squares() function when loss is nonlinear, indiciating the value of the soft margin between inlier and outlier residuals.\n",
    "    loss - string for loss parameter in least_squares().\n",
    "    init - initial slope guess for the parallel slope parameter\n",
    "    lb - Lower bound of allowed value for the slope of the regression, default -100\n",
    "    ub - Upper bound of allowed value for the slope of the regression, default -1/100\n",
    "    file_index - Index of file if cycling through an array of filenames, displayed in figure titles for a given file. Allows us to easily pick out strange cases for investigation.\n",
    "    model - model function to be used in least squares. Default is the parallel model function\n",
    "    res - Default holds the ODR residuals function to be used in least_squares(). Can hold adjusted residual functions as well.\n",
    "    odr - function that performs the orthogonal regression. Replace with great care if you do.\n",
    "    zeros - Default is None. If changed, this will keep all the canopy height = 0 and Ev = 0 outliers in the data.\n",
    "    beam - Default is None. Put in input in the form of an array of integers. For example, if you only want to display pv/pg on the plot for Beams 3 and 4, the input is [3,4]\n",
    "    y_init - This is the function used to initialize the guess for the y intercept. Default is simply the maximum value, as this is expected to correspond with the data point closest to the y-intercept.\n",
    "    graph_detail - Default is 0. If set to 1, will show a single pv/pg plot for all chosen, available beams. If set to 2, will also show each available groundtrack.\n",
    "    canopy_frac - Default is None. If changed, this will say in the title of the groundtrack what percentage of the data has canopy photon data. Low canopy fraction could indicate poor quality data. This is only displayed if Detail = 2.\n",
    "    keep_flagged - Default is True. If None, we throw out tracks that have segments with zero photon returns.\n",
    "    \"\"\"\n",
    "\n",
    "    polygon = make_box(coords, width,height)\n",
    "    min_lon, min_lat, max_lon, max_lat = polygon.total_bounds\n",
    "\n",
    "    lats = np.arange(min_lat-small_box/2, max_lat+small_box/2, small_box)\n",
    "    lons = np.arange(min_lon-small_box/(2*np.cos(np.radians(coords[1]))),\\\n",
    "                     max_lon+small_box/(2*np.cos(np.radians(coords[1]))),\\\n",
    "                     small_box/np.cos(np.radians(coords[1])))\n",
    "    \n",
    "    foldername = dirpath.split('/')[-2]\n",
    "    # print(lats, lons)\n",
    "    \n",
    "    # This will hold all of the data in one place:\n",
    "    # [[Eg, Ev, Beam 1],...[Eg,Ev,Beam 1],[Eg,Ev,Beam 2],...,[Eg,Ev,Beam6],[Eg,Ev,Beam 6]]\n",
    "    # This will be made into a dataframe later.\n",
    "    meanEgstrong = [[] for _ in range(len(lats)*len(lons))]\n",
    "    meanEgweak = [[] for _ in range(len(lats)*len(lons))]\n",
    "    meanEvstrong = [[] for _ in range(len(lats)*len(lons))]\n",
    "    meanEvweak = [[] for _ in range(len(lats)*len(lons))]\n",
    "\n",
    "    msw_flag = [[] for _ in range(len(lats)*len(lons))]\n",
    "    night_flag = [[] for _ in range(len(lats)*len(lons))]\n",
    "    asr = [[] for _ in range(len(lats)*len(lons))]\n",
    "    \n",
    "    dataset = [[] for _ in range(len(lats)*len(lons))]\n",
    "    \n",
    "    # Holds all of the X data to plot later.\n",
    "    plotX = [[] for _ in range(len(lats)*len(lons))]\n",
    "    \n",
    "    # Holds all of the Y data to plot later.\n",
    "    plotY = [[] for _ in range(len(lats)*len(lons))]\n",
    "    \n",
    "    # Holds all of the ATL03 objects to plot groundtracks later\n",
    "    atl03s = [[] for _ in range(len(lats)*len(lons))]\n",
    "\n",
    "    # To find the starting slope guess\n",
    "    slope_init = [[] for _ in range(len(lats)*len(lons))]\n",
    "    slope_weight = [[] for _ in range(len(lats)*len(lons))]\n",
    "\n",
    "    data_amount = np.zeros(len(lats)*len(lons))\n",
    "    \n",
    "#     for i in range(len(lats)*len(lons)):\n",
    "#         dataset.append([])\n",
    "#         plotX.append([])\n",
    "#         plotY.append([])\n",
    "#         msw_flag.append([])\n",
    "#         night_flag.append([])\n",
    "#         asr.append([])\n",
    "#         atl03s.append([])\n",
    "    \n",
    "    # Check the satellite orientation so we know which beams are strong and weak.\n",
    "    # Listed from Beam 1 to Beam 6 in the tracks array\n",
    "    A = h5py.File(atl03path, 'r')\n",
    "    if list(A['orbit_info']['sc_orient'])[0] == 1:\n",
    "    \tstrong = ['gt1r', 'gt2r', 'gt3r']\n",
    "    \tweak = ['gt1l', 'gt2l', 'gt3l']\n",
    "    elif list(A['orbit_info']['sc_orient'])[0] == 0:\n",
    "        strong = ['gt3l', 'gt2l', 'gt1l']\n",
    "        weak = ['gt3r', 'gt2r', 'gt1r']\n",
    "    else:\n",
    "        print('Satellite in transition orientation.')\n",
    "        A.close()\n",
    "        return 0, 0, 0, 0, 0, 0\n",
    "    tracks = [strong[0], weak[0], strong[1], weak[1], strong[2], weak[2]]\n",
    "    \n",
    "    # The only purpose of this is to keep the data organised later.\n",
    "    beam_names = [f\"Beam {i}\" for i in range(1,7)]\n",
    "    \n",
    "    # Very quick quality check; if any of the segments have zero return photons at all,\n",
    "    # the file is just skipped on assumptions that the data quality isn't good\n",
    "#     if keep_flagged == None:\n",
    "#         for gt in tracks:\n",
    "#             try:\n",
    "#                 if 0 in A[gt]['geolocation']['ph_index_beg']:\n",
    "#                     print('File ' + str(file_index) + ' has been skipped because some segments contain zero photon returns.')\n",
    "#                     A.close()\n",
    "#                     return 0, 0, 0, 0, 0, 0\n",
    "#                 # This block will be executed if 0 is found in the list\n",
    "#             except (KeyError, FileNotFoundError):\n",
    "#             # Handle the exception (e.g., print a message or log the error)\n",
    "#                 continue\n",
    "\n",
    "    A.close()\n",
    "\n",
    "    #Keep indices of colors to plot regression lines later:\n",
    "    colors = [[] for _ in range(len(lats)*len(lons))]\n",
    "    \n",
    "    # Extracting date and time from the filename\n",
    "    mid_date = parse_filename_datetime(atl03path)\n",
    "    title_date = datetime_to_title(mid_date)\n",
    "    table_date = datetime_to_date(mid_date)\n",
    "    \n",
    "    # Holds the maximum of the successfully read Ev values to use as y-intercept\n",
    "    # guesses in the regression\n",
    "    intercepts = [[] for _ in range(len(lats)*len(lons))]\n",
    "    maxes = [[] for _ in range(len(lats)*len(lons))]\n",
    "    \n",
    "    # Now that we have assurances that the data is good quality,\n",
    "    # we loop through the ground tracks\n",
    "    for i, gt in enumerate(tracks):\n",
    "        \n",
    "        # If the object fails to be created, we put worthless information into\n",
    "        # plotX, plotY, and canopy_frac to save us looping effort later\n",
    "        try:\n",
    "#             print(atl03path, gt, atl08path)\n",
    "            atl03 = get_atl03_struct(atl03path, gt, atl08path)\n",
    "        except (KeyError, ValueError, OSError) as e:\n",
    "            for k in range(len(lats)*len(lons)):\n",
    "                plotX[k].append([])\n",
    "                plotY[k].append([])\n",
    "            # msw_flag = np.concatenate((msw_flag,-1))\n",
    "            # night_flag = np.concatenate((night_flag,-1))\n",
    "            # asr = np.concatenate((asr,-1))\n",
    "                msw_flag[k].append(-1)\n",
    "                night_flag[k].append(-1)\n",
    "                asr[k].append(-1)\n",
    "                if i % 2 == 0:\n",
    "                    meanEgstrong[k].append(-1)\n",
    "                    meanEvstrong[k].append(-1)\n",
    "                else:\n",
    "                    meanEgweak[k].append(-1)\n",
    "                    meanEvweak[k].append(-1)\n",
    "            print(f\"Failed to open ATL03 file for file {file_index}'s beam {i+1}.\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            atl08 = get_atl08_struct(atl08path, gt)\n",
    "        except (KeyError, ValueError, OSError) as e:\n",
    "            for k in range(len(lats)*len(lons)):\n",
    "                plotX[k].append([])\n",
    "                plotY[k].append([])\n",
    "                msw_flag[k].append(-1)\n",
    "                night_flag[k].append(-1)\n",
    "                asr[k].append(-1)\n",
    "                if i % 2 == 0:\n",
    "                    meanEgstrong[k].append(-1)\n",
    "                    meanEvstrong[k].append(-1)\n",
    "                else:\n",
    "                    meanEgweak[k].append(-1)\n",
    "                    meanEvweak[k].append(-1)\n",
    "            print(f\"Failed to open ATL08 file for file {file_index}'s beam {i+1}.\")\n",
    "            continue\n",
    "        \n",
    "        atl03.df = atl03.df[(atl03.df['lon_ph'] >= min_lon) & (atl03.df['lon_ph'] <= max_lon) &\\\n",
    "                                (atl03.df['lat_ph'] >= min_lat) & (atl03.df['lat_ph'] <= max_lat)]\n",
    "        atl08.df = atl08.df[(atl08.df['longitude'] >= min_lon) & (atl08.df['longitude'] <= max_lon) &\\\n",
    "                                (atl08.df['latitude'] >= min_lat) & (atl08.df['latitude'] <= max_lat)]\n",
    "        \n",
    "        atl08.df = atl08.df[(atl08.df.photon_rate_can_nr < 100) & (atl08.df.photon_rate_te < 100) & (atl08.df.h_canopy < 100)]\n",
    "        \n",
    "\n",
    "        # NEW BIT FOR LAND COVER CLASSIFICATION ##############################################################################\n",
    "        # print(atl08.df['landcover'])\n",
    "        atl08.df = atl08.df[atl08.df['segment_landcover'].isin([111, 112, 113, 114, 115, 116, 121, 122, 123, 124, 125, 126])]\n",
    "        if altitude != None:\n",
    "            atl08.df = atl08.df[abs(atl08.df['h_te_best_fit'] - altitude) <= alt_thresh]\n",
    "        # print(atl08.df['landcover'])\n",
    "        \n",
    "        k = 0\n",
    "        for lat in lats:\n",
    "            for lon in lons:\n",
    "                polygon = make_box((lon,lat), small_box/2,small_box/2)\n",
    "                sub_min_lon, sub_min_lat, sub_max_lon, sub_max_lat = polygon.total_bounds\n",
    "                atl03_temp = atl03.df[(atl03.df['lon_ph'] >= sub_min_lon) & (atl03.df['lon_ph'] <= sub_max_lon) &\\\n",
    "                                        (atl03.df['lat_ph'] >= sub_min_lat) & (atl03.df['lat_ph'] <= sub_max_lat)].copy()\n",
    "                atl08_temp = atl08.df[(atl08.df['longitude'] >= sub_min_lon) & (atl08.df['longitude'] <= sub_max_lon) &\\\n",
    "                                        (atl08.df['latitude'] >= sub_min_lat) & (atl08.df['latitude'] <= sub_max_lat)].copy()\n",
    "                \n",
    "                \n",
    "                if atl08_temp.shape[0] == 0:\n",
    "                    msw_flag[k].append(-1)\n",
    "                    night_flag[k].append(-1)\n",
    "                    asr[k].append(-1)\n",
    "                    plotX[k].append([])\n",
    "                    plotY[k].append([])\n",
    "                    if i % 2 == 0:\n",
    "                        meanEgstrong[k].append(-1)\n",
    "                        meanEvstrong[k].append(-1)\n",
    "                    else:\n",
    "                        meanEgweak[k].append(-1)\n",
    "                        meanEvweak[k].append(-1)\n",
    "                    k += 1\n",
    "                    continue\n",
    "                # Retrieve the canopy fraction (fraction of segments that contain any\n",
    "                # canopy photons) if the user wants it.\n",
    "        \n",
    "                # X and Y are data for the regression\n",
    "                X = atl08_temp.photon_rate_te\n",
    "                Y = atl08_temp.photon_rate_can_nr\n",
    "        \n",
    "                # Save it for plotting after the loop goes through all the groundtracks\n",
    "                plotX[k].append(X)\n",
    "                plotY[k].append(Y)\n",
    "        \n",
    "#         if atl03.df.size != 0:\n",
    "#             # Save the ATL03 object\n",
    "#             atl03s.append(atl03)\n",
    "#             colors.append(i)\n",
    "            \n",
    "        \n",
    "                if len(Y) < threshold:\n",
    "                    print(f'Beam {i + 1}, box {k} in file {file_index} has insufficient data.')\n",
    "                    msw_flag[k].append(-1)\n",
    "                    night_flag[k].append(-1)\n",
    "                    asr[k].append(-1)\n",
    "                    if i % 2 == 0:\n",
    "                        meanEgstrong[k].append(-1)\n",
    "                        meanEvstrong[k].append(-1)\n",
    "                    else:\n",
    "                        meanEgweak[k].append(-1)\n",
    "                        meanEvweak[k].append(-1)\n",
    "                    k += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    data_amount[k] += len(Y)\n",
    "                    atl03s[k].append(atl03)\n",
    "                    colors[k].append(i)\n",
    "\n",
    "                    if i % 2 == 0:\n",
    "                        meanEgstrong[k].append(np.mean(X))\n",
    "                        meanEvstrong[k].append(np.mean(Y))\n",
    "                    else:\n",
    "                        meanEgweak[k].append(np.mean(X))\n",
    "                        meanEvweak[k].append(np.mean(Y))\n",
    "\n",
    "                    msw_flag[k].append(atl08_temp['msw_flag'].mean())\n",
    "                    night_flag[k].append(atl08_temp['night_flag'].mean())\n",
    "                    asr[k].append(atl08_temp['asr'].mean())\n",
    "            \n",
    "                # Save each individual data point from the ground track along with the Beam it belongs to.\n",
    "                for x, y in zip(X,Y):\n",
    "                    dataset[k].append([x, y, beam_names[i]])\n",
    "\n",
    "                # tweaking starting parameters\n",
    "                ############################################################\n",
    "                lower_X, lower_Y, upper_X, upper_Y = divide_arrays_2(X, Y)\n",
    "\n",
    "                y1 = np.mean(lower_Y)\n",
    "                y2 = np.mean(upper_Y)\n",
    "\n",
    "                x1 = np.mean(lower_X)\n",
    "                x2 = np.mean(upper_X)\n",
    "\n",
    "                slope, intercept = find_slope_and_intercept(x1, y1, x2, y2)\n",
    "                # print(slope)\n",
    "                if slope > -0.1:\n",
    "                    slope = -0.1\n",
    "                    intercept = intercept_from_slope_and_point(slope, (np.mean([x1,x2]),np.mean([y1,y2])))\n",
    "                elif slope < -1.5:\n",
    "                    slope = -1.5\n",
    "                    intercept = intercept_from_slope_and_point(slope, (np.mean([x1,x2]),np.mean([y1,y2])))\n",
    "                \n",
    "                slope_init[k].append(slope)\n",
    "                slope_weight[k].append(len(Y))\n",
    "                # Save the initial y_intercept guess\n",
    "                intercepts[k].append(intercept)\n",
    "                maxes[k].append(16)\n",
    "                \n",
    "                k += 1\n",
    "        #############################################################\n",
    "                continue\n",
    "            \n",
    "    rows = []\n",
    "    \n",
    "    k = 0\n",
    "    for lat in lats:\n",
    "        for lon in lons:\n",
    "            if len(dataset[k]) == 0:\n",
    "                k+=1\n",
    "                continue\n",
    "            \n",
    "            slope_weight[k] /= np.sum([slope_weight[k]])\n",
    "            slope_init[k] = np.dot(slope_init[k],slope_weight[k])\n",
    "            \n",
    "            # Create DataFrame\n",
    "            df = pd.DataFrame(dataset[k], columns=['Eg', 'Ev', 'gt'])\n",
    "            # Dummy encode the categorical variable\n",
    "            df_encoded = pd.get_dummies(df, columns=['gt'], prefix='', prefix_sep='')\n",
    "            \n",
    "            coefs = odr(df_encoded, intercepts = intercepts[k], maxes = maxes[k], init = slope_init[k],\\\n",
    "                        lb=lb, ub=ub, model = model, res = res, loss=loss, f_scale=f_scale)\n",
    "            \n",
    "            \n",
    "            if len(colors) == 0:\n",
    "                graph_detail = 0\n",
    "                \n",
    "            if graph_detail == 3:\n",
    "                plot_parallel(atl03s = atl03s[k],\n",
    "                              coefs = coefs,\n",
    "                              colors = colors[k],\n",
    "                              title_date = title_date,\n",
    "                              X = plotX[k],\n",
    "                              Y = plotY[k],\n",
    "                              beam = beam,\n",
    "                              file_index = file_index,\n",
    "                              three = True)\n",
    "                \n",
    "            elif graph_detail == 2:\n",
    "                plot_parallel(atl03s = atl03s[k],\n",
    "                              coefs = coefs,\n",
    "                              colors = colors[k],\n",
    "                              title_date = title_date,\n",
    "                              X = plotX[k],\n",
    "                              Y = plotY[k],\n",
    "                              beam = beam,\n",
    "                              file_index = file_index)\n",
    "\n",
    "            # Activate this if you don't want the groundtracks, just the plot\n",
    "            elif graph_detail == 1:\n",
    "                plot_graph(coefs = coefs,\n",
    "                           colors = colors[k],\n",
    "                           title_date = title_date,\n",
    "                           X = plotX[k],\n",
    "                           Y = plotY[k],\n",
    "                           beam = beam,\n",
    "                           file_index = file_index)\n",
    "            \n",
    "            means = [meanEgstrong[k], meanEgweak[k], meanEvstrong[k], meanEvweak[k]]\n",
    "            indices_to_insert = [i + 1 for i, entry in enumerate(asr[k]) if entry == -1]\n",
    "            for index in indices_to_insert:\n",
    "                coefs = np.insert(coefs, index, -1)\n",
    "            \n",
    "            \n",
    "            rows.append(flatten_structure([foldername, table_date, coefs, [lon,lat],means,msw_flag[k],night_flag[k],asr[k],data_amount[k]]))\n",
    "            #print([mid_date, coefs, [lon,lat],means,msw_flag[k],night_flag[k],asr[k],data_amount[k]])\n",
    "            k+=1\n",
    "    \n",
    "    BIG_DF = pd.DataFrame(rows,columns=['camera','date','pvpg','y-int1','y-int2','y-int3','y-int4','y-int5','y-int6',\\\n",
    "                                        'longitude','latitude','meanEg1','meanEg3','meanEg5','meanEg2','meanEg4',\\\n",
    "                                        'meanEg6','meanEv1','meanEv3','meanEv5','meanEv2','meanEv4','meanEv6',\\\n",
    "                                        'msw1','msw2','msw3','msw4','msw5','msw6','night1','night2','night3',\\\n",
    "                                        'night4','night5','night6','asr1','asr2','asr3','asr4','asr5','asr6','data_quantity'])\n",
    "            \n",
    "    return BIG_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed205e9",
   "metadata": {},
   "source": [
    "# FSC Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f9512dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.FSC_dataframe_phoreal import *\n",
    "from scripts.parallel_blocked import *\n",
    "\n",
    "def FSC_dataframe(dirpath, csv_path, width=.05, height=.05, graph_detail = 0, threshold=10):\n",
    "    all_ATL03, all_ATL08 = track_pairs(dirpath)\n",
    "    N = len(all_ATL03)\n",
    "\n",
    "    foldername = dirpath.split('/')[-2]\n",
    "    \n",
    "    excel_df = pd.read_csv(csv_path).drop('Image', axis=1)\n",
    "\n",
    "    FSCs = []\n",
    "    tree_snows = []\n",
    "    joint_snows = []\n",
    "    confidences = []\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for i, (atl03_filepath, atl08_filepath) in enumerate(zip(all_ATL03, all_ATL08)):\n",
    "        filedate = datetime_to_date(parse_filename_datetime(atl03_filepath))\n",
    "        if ((excel_df['Date'] == filedate) & (excel_df['Camera'] == foldername)).any():\n",
    "            coords = (excel_df.loc[(excel_df['Date'] == filedate) & (excel_df['Camera'] == foldername), 'x_coord'].iloc[0],\\\n",
    "                      excel_df.loc[(excel_df['Date'] == filedate) & (excel_df['Camera'] == foldername), 'y_coord'].iloc[0])\n",
    "            altitude = excel_df.loc[(excel_df['Date'] == filedate) & (excel_df['Camera'] == foldername), 'Altitude'].iloc[0]\n",
    "            DF = pvpg_parallel(dirpath, all_ATL03[int(i)], all_ATL08[int(i)],\n",
    "                                                                coords = coords,width=width,height=height,\n",
    "                                                                file_index = int(i),loss='arctan', graph_detail=graph_detail,\n",
    "                                                               altitude=altitude, threshold=threshold)\n",
    "            \n",
    "            DF['FSC']=excel_df.loc[(excel_df['Date'] == filedate) & (excel_df['Camera'] == foldername), 'FSC'].iloc[0]\n",
    "            DF['TreeSnow']=excel_df.loc[(excel_df['Date']==filedate) & (excel_df['Camera']==foldername), 'Tree Snow'].iloc[0]\n",
    "            DF['JointSnow']=DF['FSC'] + DF['TreeSnow']\n",
    "            DF['Confidence']=excel_df.loc[(excel_df['Date']==filedate) & (excel_df['Camera']==foldername), 'Certainty'].iloc[0]\n",
    "            \n",
    "            dfs.append(DF)\n",
    "    \n",
    "    dfs_non_empty = [df for df in dfs if not df.empty]\n",
    "    \n",
    "    combined_df = pd.concat(dfs_non_empty, ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f218fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam 1, box 562 in file 0 has insufficient data.\n",
      "Beam 1, box 604 in file 0 has insufficient data.\n",
      "Beam 1, box 1065 in file 0 has insufficient data.\n",
      "Beam 1, box 1107 in file 0 has insufficient data.\n",
      "Failed to open ATL08 file for file 0's beam 2.\n",
      "Failed to open ATL03 file for file 0's beam 3.\n",
      "Failed to open ATL03 file for file 0's beam 4.\n",
      "Failed to open ATL03 file for file 0's beam 5.\n",
      "Failed to open ATL03 file for file 0's beam 6.\n",
      "Beam 1, box 694 in file 1 has insufficient data.\n",
      "Beam 4, box 573 in file 1 has insufficient data.\n",
      "Beam 4, box 615 in file 1 has insufficient data.\n",
      "Failed to open ATL03 file for file 1's beam 5.\n",
      "Failed to open ATL03 file for file 1's beam 6.\n",
      "Failed to open ATL03 file for file 2's beam 1.\n",
      "Failed to open ATL03 file for file 2's beam 2.\n",
      "Failed to open ATL03 file for file 2's beam 3.\n",
      "Failed to open ATL03 file for file 2's beam 4.\n",
      "Beam 5, box 613 in file 2 has insufficient data.\n",
      "Beam 5, box 655 in file 2 has insufficient data.\n",
      "Beam 5, box 738 in file 2 has insufficient data.\n",
      "Beam 5, box 780 in file 2 has insufficient data.\n",
      "Beam 5, box 822 in file 2 has insufficient data.\n",
      "Failed to open ATL03 file for file 3's beam 1.\n",
      "Failed to open ATL03 file for file 3's beam 2.\n",
      "Failed to open ATL03 file for file 3's beam 3.\n",
      "Failed to open ATL03 file for file 3's beam 4.\n",
      "Beam 5, box 559 in file 3 has insufficient data.\n",
      "Beam 5, box 686 in file 3 has insufficient data.\n",
      "Beam 5, box 770 in file 3 has insufficient data.\n",
      "Beam 5, box 938 in file 3 has insufficient data.\n",
      "Beam 6, box 559 in file 3 has insufficient data.\n",
      "Beam 2, box 730 in file 4 has insufficient data.\n",
      "Failed to open ATL03 file for file 4's beam 3.\n",
      "Failed to open ATL03 file for file 4's beam 4.\n",
      "Failed to open ATL03 file for file 4's beam 5.\n",
      "Failed to open ATL03 file for file 4's beam 6.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera</th>\n",
       "      <th>date</th>\n",
       "      <th>pvpg</th>\n",
       "      <th>y-int1</th>\n",
       "      <th>y-int2</th>\n",
       "      <th>y-int3</th>\n",
       "      <th>y-int4</th>\n",
       "      <th>y-int5</th>\n",
       "      <th>y-int6</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>asr2</th>\n",
       "      <th>asr3</th>\n",
       "      <th>asr4</th>\n",
       "      <th>asr5</th>\n",
       "      <th>asr6</th>\n",
       "      <th>data_quantity</th>\n",
       "      <th>FSC</th>\n",
       "      <th>TreeSnow</th>\n",
       "      <th>JointSnow</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>27/03/2019</td>\n",
       "      <td>-9.644074e-01</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.575699</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>13/04/2019</td>\n",
       "      <td>-9.927508e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.96481</td>\n",
       "      <td>1.100212</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.731579</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.276156</td>\n",
       "      <td>0.288002</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>13/04/2019</td>\n",
       "      <td>-1.077245e+00</td>\n",
       "      <td>3.723724</td>\n",
       "      <td>1.154462</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.653639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301795</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>13/04/2019</td>\n",
       "      <td>-9.280556e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.118311</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.731579</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.250608</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>13/04/2019</td>\n",
       "      <td>-7.723256e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.048317</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.653639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329290</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>13/04/2019</td>\n",
       "      <td>-2.670694e-01</td>\n",
       "      <td>1.036240</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.653639</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>25/04/2019</td>\n",
       "      <td>-4.369361e-18</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.228315</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.692609</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.321280</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>25/04/2019</td>\n",
       "      <td>-5.290882e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.573785</td>\n",
       "      <td>26.692609</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.323829</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>25/04/2019</td>\n",
       "      <td>-2.252796e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.842658</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.679619</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.243961</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>25/04/2019</td>\n",
       "      <td>-4.342797e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.441849</td>\n",
       "      <td>0.458926</td>\n",
       "      <td>26.679619</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.205805</td>\n",
       "      <td>0.384790</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>25/04/2019</td>\n",
       "      <td>-2.568504e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.140371</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.679619</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.216968</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-1.037956e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.634109</td>\n",
       "      <td>26.536729</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.073705</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-4.311844e-02</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.367745</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.549719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.139826</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-2.052433e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.541684</td>\n",
       "      <td>26.536729</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.104626</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-1.360899e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.996547</td>\n",
       "      <td>0.439184</td>\n",
       "      <td>26.549719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.113273</td>\n",
       "      <td>0.092077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-9.394023e-17</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.288544</td>\n",
       "      <td>26.549719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.091514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-1.079855e-24</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.443728</td>\n",
       "      <td>0.360484</td>\n",
       "      <td>26.549719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.083298</td>\n",
       "      <td>0.113068</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-9.102038e-02</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.580136</td>\n",
       "      <td>0.366996</td>\n",
       "      <td>26.549719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.097673</td>\n",
       "      <td>0.080632</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-4.446895e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.038174</td>\n",
       "      <td>0.496050</td>\n",
       "      <td>26.549719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.101447</td>\n",
       "      <td>0.076694</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-4.412492e-23</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.273269</td>\n",
       "      <td>26.549719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.163320</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-5.616794e-27</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.854085</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.562709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.106848</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-3.983282e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.057904</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.562709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.103223</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-9.652410e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.616004</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.562709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.091925</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-2.785011e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.659525</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.562709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.105651</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>-8.967010e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.258647</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.562709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.067165</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sodankyla_test</td>\n",
       "      <td>26/06/2019</td>\n",
       "      <td>-4.847278e-22</td>\n",
       "      <td>0.369146</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>26.575699</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows  46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            camera        date          pvpg    y-int1    y-int2   y-int3  \\\n",
       "0   sodankyla_test  27/03/2019 -9.644074e-01  0.338130 -1.000000 -1.00000   \n",
       "1   sodankyla_test  13/04/2019 -9.927508e-01 -1.000000 -1.000000  2.96481   \n",
       "2   sodankyla_test  13/04/2019 -1.077245e+00  3.723724  1.154462 -1.00000   \n",
       "3   sodankyla_test  13/04/2019 -9.280556e-01 -1.000000 -1.000000 -1.00000   \n",
       "4   sodankyla_test  13/04/2019 -7.723256e-01 -1.000000  1.048317 -1.00000   \n",
       "5   sodankyla_test  13/04/2019 -2.670694e-01  1.036240 -1.000000 -1.00000   \n",
       "6   sodankyla_test  25/04/2019 -4.369361e-18 -1.000000 -1.000000 -1.00000   \n",
       "7   sodankyla_test  25/04/2019 -5.290882e-01 -1.000000 -1.000000 -1.00000   \n",
       "8   sodankyla_test  25/04/2019 -2.252796e+00 -1.000000 -1.000000 -1.00000   \n",
       "9   sodankyla_test  25/04/2019 -4.342797e-01 -1.000000 -1.000000 -1.00000   \n",
       "10  sodankyla_test  25/04/2019 -2.568504e-01 -1.000000 -1.000000 -1.00000   \n",
       "11  sodankyla_test  14/06/2019 -1.037956e+00 -1.000000 -1.000000 -1.00000   \n",
       "12  sodankyla_test  14/06/2019 -4.311844e-02 -1.000000 -1.000000 -1.00000   \n",
       "13  sodankyla_test  14/06/2019 -2.052433e-01 -1.000000 -1.000000 -1.00000   \n",
       "14  sodankyla_test  14/06/2019 -1.360899e-01 -1.000000 -1.000000 -1.00000   \n",
       "15  sodankyla_test  14/06/2019 -9.394023e-17 -1.000000 -1.000000 -1.00000   \n",
       "16  sodankyla_test  14/06/2019 -1.079855e-24 -1.000000 -1.000000 -1.00000   \n",
       "17  sodankyla_test  14/06/2019 -9.102038e-02 -1.000000 -1.000000 -1.00000   \n",
       "18  sodankyla_test  14/06/2019 -4.446895e-01 -1.000000 -1.000000 -1.00000   \n",
       "19  sodankyla_test  14/06/2019 -4.412492e-23 -1.000000 -1.000000 -1.00000   \n",
       "20  sodankyla_test  14/06/2019 -5.616794e-27 -1.000000 -1.000000 -1.00000   \n",
       "21  sodankyla_test  14/06/2019 -3.983282e-01 -1.000000 -1.000000 -1.00000   \n",
       "22  sodankyla_test  14/06/2019 -9.652410e-01 -1.000000 -1.000000 -1.00000   \n",
       "23  sodankyla_test  14/06/2019 -2.785011e+00 -1.000000 -1.000000 -1.00000   \n",
       "24  sodankyla_test  14/06/2019 -8.967010e-01 -1.000000 -1.000000 -1.00000   \n",
       "25  sodankyla_test  26/06/2019 -4.847278e-22  0.369146 -1.000000 -1.00000   \n",
       "\n",
       "      y-int4    y-int5    y-int6  longitude  ...      asr2      asr3  \\\n",
       "0  -1.000000 -1.000000 -1.000000  26.575699  ... -1.000000 -1.000000   \n",
       "1   1.100212 -1.000000 -1.000000  26.731579  ... -1.000000  0.276156   \n",
       "2  -1.000000 -1.000000 -1.000000  26.653639  ...  0.301795 -1.000000   \n",
       "3   1.118311 -1.000000 -1.000000  26.731579  ... -1.000000 -1.000000   \n",
       "4  -1.000000 -1.000000 -1.000000  26.653639  ...  0.329290 -1.000000   \n",
       "5  -1.000000 -1.000000 -1.000000  26.653639  ... -1.000000 -1.000000   \n",
       "6  -1.000000  0.228315 -1.000000  26.692609  ... -1.000000 -1.000000   \n",
       "7  -1.000000 -1.000000  0.573785  26.692609  ... -1.000000 -1.000000   \n",
       "8  -1.000000  6.842658 -1.000000  26.679619  ... -1.000000 -1.000000   \n",
       "9  -1.000000  1.441849  0.458926  26.679619  ... -1.000000 -1.000000   \n",
       "10 -1.000000  1.140371 -1.000000  26.679619  ... -1.000000 -1.000000   \n",
       "11 -1.000000 -1.000000  0.634109  26.536729  ... -1.000000 -1.000000   \n",
       "12 -1.000000  1.367745 -1.000000  26.549719  ... -1.000000 -1.000000   \n",
       "13 -1.000000 -1.000000  0.541684  26.536729  ... -1.000000 -1.000000   \n",
       "14 -1.000000  0.996547  0.439184  26.549719  ... -1.000000 -1.000000   \n",
       "15 -1.000000 -1.000000  0.288544  26.549719  ... -1.000000 -1.000000   \n",
       "16 -1.000000  0.443728  0.360484  26.549719  ... -1.000000 -1.000000   \n",
       "17 -1.000000  0.580136  0.366996  26.549719  ... -1.000000 -1.000000   \n",
       "18 -1.000000  1.038174  0.496050  26.549719  ... -1.000000 -1.000000   \n",
       "19 -1.000000 -1.000000  0.273269  26.549719  ... -1.000000 -1.000000   \n",
       "20 -1.000000  0.854085 -1.000000  26.562709  ... -1.000000 -1.000000   \n",
       "21 -1.000000  1.057904 -1.000000  26.562709  ... -1.000000 -1.000000   \n",
       "22 -1.000000  1.616004 -1.000000  26.562709  ... -1.000000 -1.000000   \n",
       "23 -1.000000  3.659525 -1.000000  26.562709  ... -1.000000 -1.000000   \n",
       "24 -1.000000  1.258647 -1.000000  26.562709  ... -1.000000 -1.000000   \n",
       "25 -1.000000 -1.000000 -1.000000  26.575699  ... -1.000000 -1.000000   \n",
       "\n",
       "        asr4      asr5      asr6  data_quantity  FSC  TreeSnow  JointSnow  \\\n",
       "0  -1.000000 -1.000000 -1.000000            2.0  1.0       0.0        1.0   \n",
       "1   0.288002 -1.000000 -1.000000            6.0  1.0       0.0        1.0   \n",
       "2  -1.000000 -1.000000 -1.000000            6.0  1.0       0.0        1.0   \n",
       "3   0.250608 -1.000000 -1.000000            4.0  1.0       0.0        1.0   \n",
       "4  -1.000000 -1.000000 -1.000000            3.0  1.0       0.0        1.0   \n",
       "5  -1.000000 -1.000000 -1.000000            3.0  1.0       0.0        1.0   \n",
       "6  -1.000000  0.321280 -1.000000            2.0  1.0       0.0        1.0   \n",
       "7  -1.000000 -1.000000  0.323829            5.0  1.0       0.0        1.0   \n",
       "8  -1.000000  0.243961 -1.000000            2.0  1.0       0.0        1.0   \n",
       "9  -1.000000  0.205805  0.384790            8.0  1.0       0.0        1.0   \n",
       "10 -1.000000  0.216968 -1.000000            3.0  1.0       0.0        1.0   \n",
       "11 -1.000000 -1.000000  0.073705            5.0  0.0       0.0        0.0   \n",
       "12 -1.000000  0.139826 -1.000000            4.0  0.0       0.0        0.0   \n",
       "13 -1.000000 -1.000000  0.104626            3.0  0.0       0.0        0.0   \n",
       "14 -1.000000  0.113273  0.092077            9.0  0.0       0.0        0.0   \n",
       "15 -1.000000 -1.000000  0.091514            2.0  0.0       0.0        0.0   \n",
       "16 -1.000000  0.083298  0.113068            5.0  0.0       0.0        0.0   \n",
       "17 -1.000000  0.097673  0.080632            7.0  0.0       0.0        0.0   \n",
       "18 -1.000000  0.101447  0.076694            5.0  0.0       0.0        0.0   \n",
       "19 -1.000000 -1.000000  0.163320            3.0  0.0       0.0        0.0   \n",
       "20 -1.000000  0.106848 -1.000000            6.0  0.0       0.0        0.0   \n",
       "21 -1.000000  0.103223 -1.000000            5.0  0.0       0.0        0.0   \n",
       "22 -1.000000  0.091925 -1.000000            6.0  0.0       0.0        0.0   \n",
       "23 -1.000000  0.105651 -1.000000            5.0  0.0       0.0        0.0   \n",
       "24 -1.000000  0.067165 -1.000000            3.0  0.0       0.0        0.0   \n",
       "25 -1.000000 -1.000000 -1.000000            2.0  0.0       0.0        0.0   \n",
       "\n",
       "    Confidence  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  \n",
       "5          1.0  \n",
       "6          1.0  \n",
       "7          1.0  \n",
       "8          1.0  \n",
       "9          1.0  \n",
       "10         1.0  \n",
       "11         1.0  \n",
       "12         1.0  \n",
       "13         1.0  \n",
       "14         1.0  \n",
       "15         1.0  \n",
       "16         1.0  \n",
       "17         1.0  \n",
       "18         1.0  \n",
       "19         1.0  \n",
       "20         1.0  \n",
       "21         1.0  \n",
       "22         1.0  \n",
       "23         1.0  \n",
       "24         1.0  \n",
       "25         1.0  \n",
       "\n",
       "[26 rows x 46 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.FSC_dataframe_phoreal import *\n",
    "\n",
    "# dirpaths = ['../data_store/data/marcell_MN/']\n",
    "dirpaths = ['../data/sodankyla_test/']\n",
    "\n",
    "csvpath = 'snow_cam_details.csv'\n",
    "\n",
    "for i, dirpath in enumerate(dirpaths):\n",
    "    if i == 0:\n",
    "        df = FSC_dataframe(dirpath, csvpath, width=.1, height=.1, graph_detail=0, threshold=2, small_box=.005)\n",
    "    else:\n",
    "        df_ = FSC_dataframe(dirpath, csvpath, width=.1, height=.1, graph_detail=0, threshold=2, small_box=.005)\n",
    "        df = pd.concat([df, df_], axis=0)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
