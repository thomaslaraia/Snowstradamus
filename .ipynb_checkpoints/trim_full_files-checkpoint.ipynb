{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b631814f-2863-47a6-bee8-d08f09fc9f21",
   "metadata": {},
   "source": [
    "### Change classes_fixed.py such that subset_can_flag, subset_te_flag, msw_flag, night_flag, and asr are pulled into atl08.df. Then I don't need to call B at all, and the information will be true for the subset of the information we selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ef5dcd8-d50c-4b47-9797-ddb000ac9ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               lon        lat          z         h  conf  classification\n",
      "0        34.325040  79.994183  21.844212  0.268011     4             1.0\n",
      "1        34.325009  79.994159  21.638750  0.076965     4             1.0\n",
      "2        34.325001  79.994152  21.575979  0.029509     4             1.0\n",
      "3        34.324993  79.994146  21.308960 -0.221451     4             1.0\n",
      "4        34.324985  79.994140  21.637541  0.123928     4             1.0\n",
      "...            ...        ...        ...       ...   ...             ...\n",
      "1547406  24.884518  59.496783  41.233471 -0.442242     4             1.0\n",
      "1547407  24.884518  59.496783  41.654690 -0.023254     4             1.0\n",
      "1547408  24.884517  59.496777  41.464947 -0.215122     4             1.0\n",
      "1547409  24.884516  59.496771  41.545670 -0.136417     4             1.0\n",
      "1547410  24.884514  59.496764  41.736588  0.052582     4             1.0\n",
      "\n",
      "[1547411 rows x 6 columns]\n",
      "            lat        lon         gh         ch   Ng   Nv        Eg        Ev\n",
      "15    79.980629  34.308006  20.727026   4.229359  128   26  1.280000  0.270000\n",
      "21    79.975372  34.301437  21.286402   2.397675  145   25  1.380952  0.247619\n",
      "29    79.968369  34.292648  20.562325   1.687174  100   77  0.884956  0.690265\n",
      "43    79.956116  34.277336  21.811325   3.344362  133   21  1.330000  0.220000\n",
      "54    79.946487  34.265316  20.654047   2.874315  121   45  1.110092  0.834862\n",
      "...         ...        ...        ...        ...  ...  ...       ...       ...\n",
      "5685  59.502216  24.885614  37.016411  16.048580   50  133  0.450450  1.423423\n",
      "5686  59.501324  24.885431  37.564270  19.319729   73   79  0.722772  0.851485\n",
      "5687  59.500431  24.885250  38.295193  22.574192   68  102  0.618182  1.200000\n",
      "5688  59.499535  24.885069  39.789749  27.078712   39  128  0.371429  1.571429\n",
      "5689  59.498642  24.884890  40.326000  25.116531   59   81  0.595960  1.121212\n",
      "\n",
      "[3301 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, box as shapely_box\n",
    "import simplekml\n",
    "from scripts.track_pairs import *\n",
    "\n",
    "def make_box(coords, width=2, height=2):\n",
    "    w = width\n",
    "    h = height\n",
    "    polygon = gpd.GeoDataFrame(geometry=[box(coords[0]-w, coords[1]-h, coords[0]+w, coords[1]+h)], crs=\"EPSG:4326\")\n",
    "\n",
    "    return polygon\n",
    "\n",
    "dirpath = '../data/sodankyla_full/'\n",
    "\n",
    "data = []\n",
    "\n",
    "all_ATL03, all_ATL08 = track_pairs(dirpath)\n",
    "N = len(all_ATL03)\n",
    "\n",
    "atl03 = ATL03(all_ATL03[0],all_ATL08[0],'gt1r')\n",
    "atl08 = ATL08(all_ATL08[0], 'gt1r')\n",
    "\n",
    "print(atl03.df)\n",
    "print(atl08.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008fff89-772a-4938-b365-9a6a87a9a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.imports import os, glob, pdb, np, h5py, pd, xr, gpd, Proj, Transformer, CRS, \\\n",
    "                        plt, cmap, cmap2, Model, Data, ODR, datetime, rasterio, show, \\\n",
    "                        ccrs, cfeature\n",
    "from scripts.classes_fixed import *\n",
    "from scripts.pvpg_concise import *\n",
    "from scripts.show_tracks import *\n",
    "from scipy.optimize import least_squares\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scripts.odr import odr\n",
    "\n",
    "\n",
    "# This function is called if the graph_detail is set to 2!\n",
    "# I know I used different coding structure for this one but\n",
    "# all I can really say is whoops and move on.\n",
    "def plot_parallel(atl03s, coefs, colors, title_date, X, Y, beam = None, canopy_frac = None, terrain_frac = None, file_index=None, three=None):\n",
    "    \"\"\"\n",
    "    Plotting function of pvpg_parallel. Shows a regression line for each available groudntrack in a bigger plot, as well as groundtrack visualisations in a smaller plot.\n",
    "    \n",
    "    atl03s - This is an array of ATL03 objects, one for each groundtrack that was successfully turned into an object. If only Beams 5 and 6 exist, then this has two objects in it, one for each of those beams.\n",
    "    coefs - Array of parameters that are optimized, starting with the slope in coefs[0] and another parameter for each beam to control the y-intercept.\n",
    "    colors - This holds the integers minus one of the beams that have groundtracks in the file. This is to keep the coloring in the plots consistent for each beam across all files.\n",
    "    title_date - This is just the data and time of the ICESat-2 overpass. The parse_filename_datetime() function will take care of this for you.\n",
    "    X - Array of each Eg dataset, [[data1],[data2],...]. This always has six arrays in it, one for each groundtrack from Beam 1 to Beam 6. If nothing is read, you get an empty array [], e.g. [[data1],[],[data3],...]\n",
    "    Y - Array of each Ev dataset, see X description.\n",
    "    beam - An array of beams to focus on. For example, if you only want to see pv/pg information on the plot for Beams 3 and 4, then you would set beam = [3,4]. Default is None, and all beams are shown.\n",
    "    file_index - Default set to None. If changed, this will show the index of the file in an array of all ATL03 file paths so that it is easy to find and focus on interesting cases. Works if you are in a loop of filepaths and you need to know which one is being funky.\n",
    "    canopy_frac - Default is None. If changed, this will say in the title of the groundtrack what percentage of the data has canopy photon data. Low canopy fraction could indicate poor quality data. This is only displayed if Detail = 2.\n",
    "    \"\"\"\n",
    "\n",
    "    # Simple array of all the beam names\n",
    "    beam_names = [f\"Beam {i}\" for i in range(1,7)]\n",
    "    \n",
    "    # Six small figures for groundtracks and one for the pv/pg plot\n",
    "    fig = plt.figure(figsize=(10, 12))\n",
    "    if three == None:\n",
    "        ax1 = fig.add_subplot(331)\n",
    "        ax2 = fig.add_subplot(332)\n",
    "        ax3 = fig.add_subplot(334)\n",
    "        ax4 = fig.add_subplot(335)\n",
    "        ax5 = fig.add_subplot(337)\n",
    "        ax6 = fig.add_subplot(338)\n",
    "        ax7 = fig.add_subplot(133)\n",
    "    else:\n",
    "        ax1 = fig.add_subplot(321)\n",
    "        ax2 = fig.add_subplot(322)\n",
    "        ax3 = fig.add_subplot(323)\n",
    "        ax4 = fig.add_subplot(324)\n",
    "        ax5 = fig.add_subplot(325)\n",
    "        ax6 = fig.add_subplot(326)\n",
    "    axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "    \n",
    "    # Set the figure title\n",
    "    if file_index != None:\n",
    "        fig.suptitle(title_date + ' - N = ' + str(file_index), fontsize=16)\n",
    "    else:\n",
    "        fig.suptitle(title_date, fontsize=16)\n",
    "    \n",
    "    # we go through each color and atl03 object together.\n",
    "    # In this loop, we plot all of the groundtracks where they belong\n",
    "    # depending on which beam it is and plot the data in the scatterplot\n",
    "    for i, c, atl03 in zip(np.arange(len(colors)),colors, atl03s):\n",
    "        \n",
    "        # If there's a canopy fraction wanted, we stick it in the title\n",
    "        if (canopy_frac != None) & (terrain_frac != None):\n",
    "            atl03.plot_small(axes[c], f\"{beam_names[c]} - TF = {round(terrain_frac[c],2)}, CF = {round(canopy_frac[c],2)}\")\n",
    "        \n",
    "        elif canopy_frac != None:\n",
    "            atl03.plot_small(axes[c], f\"{beam_names[c]} - CF = {round(canopy_frac[c],2)}\")\n",
    "        \n",
    "        elif terrain_frac != None:\n",
    "            atl03.plot_small(axes[c], f\"{beam_names[c]} - TF = {round(terrain_frac[c],2)}\")\n",
    "        \n",
    "        else:\n",
    "            atl03.plot_small(axes[c], beam_names[c])\n",
    "        \n",
    "        # If there's a focus on certain beams, we run this if statement to\n",
    "        # check if the current beam is in the list of beams the user wants.\n",
    "        # Then we throw the data onto the scatterplot with the color of choice\n",
    "        # along with a regression line of the same color\n",
    "        if three == None:\n",
    "        \n",
    "            if beam != None:\n",
    "                if c + 1 in beam:\n",
    "                    ax7.scatter(X[c],Y[c], s=5, color=cmap2(c))\n",
    "                    ax7.plot(np.array([0,12]), model([coefs[0], coefs[1+i]], np.array([0,12])), label=f\"Beam {int(c+1)}\",\\\n",
    "                        color=cmap2(c), linestyle='--', zorder=3)\n",
    "            else:\n",
    "                ax7.scatter(X[c],Y[c], s=5, color=cmap2(c))\n",
    "                ax7.plot(np.array([0,12]), model([coefs[0], coefs[1+i]], np.array([0,12])), label=f\"Beam {int(c+1)}\",\\\n",
    "                    color=cmap2(c), linestyle='--', zorder=3)\n",
    "    \n",
    "    \n",
    "    if three == None:        \n",
    "        # Show the pv/pg estimate on the plot\n",
    "        ax7.annotate(r'$\\rho_v/\\rho_g \\approx {:.2f}$'.format(-coefs[0]),\n",
    "                       xy=(.35,.98),\n",
    "                       xycoords='axes fraction',\n",
    "                       ha='right',\n",
    "                       va='top',\n",
    "                       fontsize=8,\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\",\n",
    "                                 edgecolor=\"black\",\n",
    "                                 facecolor=\"white\"))\n",
    "    \n",
    "        # Set all the boring plot details\n",
    "        ax7.set_title(f\"Ev/Eg Rates\", fontsize=8)\n",
    "        ax7.set_xlabel('Eg (returns/shot)')\n",
    "        ax7.set_ylabel('Ev (returns/shot)')\n",
    "        ax7.set_xlim(0,8)\n",
    "        ax7.set_ylim(0,40)\n",
    "        ax7.legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])  # Adjust the layout to make room for the suptitle\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "# This corresponds to graph_detail = 1\n",
    "def plot_graph(coefs, colors, title_date, X, Y, beam = None, file_index=None):\n",
    "    \"\"\"\n",
    "    Plotting function of pvpg_parallel. Shows a regression line for each available groudntrack in a bigger plot, as well as groundtrack visualisations in a smaller plot.\n",
    "    \n",
    "    coefs - Array of parameters that are optimized, starting with the slope in coefs[0] and another parameter for each beam to control the y-intercept.\n",
    "    colors - This holds the integers minus one of the beams that have groundtracks in the file. This is to keep the coloring in the plots consistent for each beam across all files.\n",
    "    title_date - This is just the data and time of the ICESat-2 overpass. The parse_filename_datetime() function will take care of this for you.\n",
    "    X - Array of each Eg dataset, [[data1],[data2],...]. This always has six arrays in it, one for each groundtrack from Beam 1 to Beam 6. If nothing is read, you get an empty array [], e.g. [[data1],[],[data3],...]\n",
    "    Y - Array of each Ev dataset, see X description.\n",
    "    beam - An array of beams to focus on. For example, if you only want to see pv/pg information on the plot for Beams 3 and 4, then you would set beam = [3,4]. Default is None, and all beams are shown.\n",
    "    file_index - Default set to None. If changed, this will show the index of the file in an array of all ATL03 file paths so that it is easy to find and focus on interesting cases. Works if you are in a loop of filepaths and you need to know which one is being funky.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Big plot that we want\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Set the figure title\n",
    "    if file_index != None:\n",
    "        fig.suptitle(title_date + ' - N = ' + str(file_index), fontsize=16)\n",
    "    else:\n",
    "        fig.suptitle(title_date, fontsize=16)\n",
    "    \n",
    "    # Plot the data and the regression lines. If the beam parameter is active,\n",
    "    # then only for the beams of interest\n",
    "    for i, c in enumerate(colors):\n",
    "        if beam != None:\n",
    "            if c + 1 in beam:\n",
    "                # scatter\n",
    "                plt.scatter(X[c],Y[c], s=5, color=cmap2(c))\n",
    "                # regress\n",
    "                plt.plot(np.array([0,12]), model([coefs[0], coefs[1+i]], np.array([0,12])), label=f\"Beam {int(c+1)}\",\\\n",
    "                    color=cmap2(c), linestyle='--', zorder=3)\n",
    "        else:\n",
    "            #scatter\n",
    "            plt.scatter(X[c],Y[c], s=5, color=cmap2(c))\n",
    "            #regress\n",
    "            plt.plot(np.array([0,12]), model([coefs[0], coefs[1+i]], np.array([0,12])), label=f\"Beam {int(c+1)}\",\\\n",
    "                color=cmap2(c), linestyle='--', zorder=3)\n",
    "    # Display the pv/pg estimate\n",
    "    plt.annotate(r'$\\rho_v/\\rho_g \\approx {:.2f}$'.format(-coefs[0]),\n",
    "                   xy=(.081,.98),\n",
    "                   xycoords='axes fraction',\n",
    "                   ha='right',\n",
    "                   va='top',\n",
    "                   fontsize=8,\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\",\n",
    "                             edgecolor=\"black\",\n",
    "                             facecolor=\"white\"))\n",
    "    \n",
    "    # Do all the boring plot display stuff\n",
    "    plt.title(f\"Ev/Eg Rates\", fontsize=8)\n",
    "    plt.xlabel('Eg (returns/shot)')\n",
    "    plt.ylabel('Ev (returns/shot)')\n",
    "    plt.xlim(0,8)\n",
    "    plt.ylim(0,8)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])  # Adjust the layout to make room for the suptitle\n",
    "    plt.show()\n",
    "\n",
    "def parallel_model(params, x):\n",
    "    # print(x)\n",
    "    common_slope, *parallel = params\n",
    "\n",
    "    # Get all columns starting with 'Beam'\n",
    "    beam_columns = [col for col in x.columns if col.startswith('Beam')]\n",
    "    return common_slope*x['Eg'] + np.dot(x[beam_columns], parallel)\n",
    "\n",
    "def parallel_residuals(params, x, y, model = parallel_model):\n",
    "    model_output = model(params, x)\n",
    "    # print(y.T.values[0])\n",
    "    return (y.T.values[0] - model_output)/np.sqrt(1 + params[0]**2)\n",
    "\n",
    "def parallel_odr(dataset, maxes, init = -1, lb = -100, ub = -1/100, model = parallel_model, res = parallel_residuals, loss='arctan', f_scale=.1):\n",
    "    \"\"\"\n",
    "    Performs the parallel orthogonal distance regression on the given dataset.\n",
    "    \n",
    "    dataset - Pandas Dataframe with columns Eg, Ev, and Beam _ for each beam with data.\n",
    "    maxes - Array that holds the initial y_intercept guess for each beam. If only Beams 5 and 6 made it, then there are only two values in this array.\n",
    "    init - Initial slope guess\n",
    "    lb - Lower bound constraint for slope\n",
    "    ub - Upper bound constraint for slope\n",
    "    model - Model to estimate Ev and Eg.\n",
    "    res - Residuals to put into least_squares function\n",
    "    loss - Loss function in regression\n",
    "    f_scale - f_scale parameter for least_squares, affects how much it cares about outliers.\n",
    "    \"\"\"\n",
    "   \n",
    "    # cats is the number of groundtracks that have data that we could read\n",
    "    cats = dataset.shape[1]-2\n",
    "    \n",
    "    # a is the lower bound of the parameters, [slope, intercept_for_first_dataset, etc.]\n",
    "    # b is the upper bound, same setup.\n",
    "    # We then put it together into a bounds variable that we can use in least_squares()\n",
    "    a = [lb] + [0]*cats\n",
    "    b = [ub] + [16]*cats\n",
    "    bounds = (a,b)\n",
    "    \n",
    "    # Initial guess [slope, y_intercept_first_dataset, y_intercept_second_dataset, etc.]\n",
    "    initial_params = [init] + maxes\n",
    "    # print(initial_params)\n",
    "    \n",
    "    # Just like in machine learning, we drop Y from the data to be our dependent variable\n",
    "    # and we keep everything else, our features, in X.\n",
    "    X = dataset.drop(columns=['Ev'])\n",
    "    Y = dataset[['Ev']]\n",
    "    \n",
    "    # We call least_squares to do the heavy lifting for us.\n",
    "    params = least_squares(res, x0=initial_params, args=(X, Y, model), loss = loss, f_scale=f_scale, bounds = bounds,\\\n",
    "        ftol = 1e-15, xtol=1e-15, gtol=1e-15).x\n",
    "    \n",
    "    # Return the resulting coefficients\n",
    "    return params\n",
    "\n",
    "def pvpg_parallel(atl03path, atl08path, coords, width=2, height=2, f_scale = .1, loss = 'arctan', init = -1, lb = -100, ub = -1/100,\\\n",
    "    file_index = None, model = parallel_model, res = parallel_residuals, odr = parallel_odr, zeros=None,\\\n",
    "    beam = None, y_init = np.max, graph_detail = 0, canopy_frac = None, terrain_frac = None, keep_flagged=None):\n",
    "    \"\"\"\n",
    "    Parallel regression of all tracks on a given overpass.\n",
    "\n",
    "    atl03path - Path/to/ATL03/file\n",
    "    atl08path - Path/to/matching/ATL08/file\n",
    "    f_scale - Parameter in least_squares() function when loss is nonlinear, indiciating the value of the soft margin between inlier and outlier residuals.\n",
    "    loss - string for loss parameter in least_squares().\n",
    "    init - initial slope guess for the parallel slope parameter\n",
    "    lb - Lower bound of allowed value for the slope of the regression, default -100\n",
    "    ub - Upper bound of allowed value for the slope of the regression, default -1/100\n",
    "    file_index - Index of file if cycling through an array of filenames, displayed in figure titles for a given file. Allows us to easily pick out strange cases for investigation.\n",
    "    model - model function to be used in least squares. Default is the parallel model function\n",
    "    res - Default holds the ODR residuals function to be used in least_squares(). Can hold adjusted residual functions as well.\n",
    "    odr - function that performs the orthogonal regression. Replace with great care if you do.\n",
    "    zeros - Default is None. If changed, this will keep all the canopy height = 0 and Ev = 0 outliers in the data.\n",
    "    beam - Default is None. Put in input in the form of an array of integers. For example, if you only want to display pv/pg on the plot for Beams 3 and 4, the input is [3,4]\n",
    "    y_init - This is the function used to initialize the guess for the y intercept. Default is simply the maximum value, as this is expected to correspond with the data point closest to the y-intercept.\n",
    "    graph_detail - Default is 0. If set to 1, will show a single pv/pg plot for all chosen, available beams. If set to 2, will also show each available groundtrack.\n",
    "    canopy_frac - Default is None. If changed, this will say in the title of the groundtrack what percentage of the data has canopy photon data. Low canopy fraction could indicate poor quality data. This is only displayed if Detail = 2.\n",
    "    keep_flagged - Default is None. If changed, we keep the tracks that were thrown out for having segments with zero photon returns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # This will hold all of the data in one place:\n",
    "    # [[Eg, Ev, Beam 1],...[Eg,Ev,Beam 1],[Eg,Ev,Beam 2],...,[Eg,Ev,Beam6],[Eg,Ev,Beam 6]]\n",
    "    # This will be made into a dataframe later.\n",
    "    meanEgstrong = []\n",
    "    meanEgweak = []\n",
    "    meanEvstrong = []\n",
    "    meanEvweak = []\n",
    "\n",
    "    msw_flag = []\n",
    "    night_flag = []\n",
    "    asr = []\n",
    "    \n",
    "    dataset = []\n",
    "    \n",
    "    # Holds all of the X data to plot later.\n",
    "    plotX = []\n",
    "    \n",
    "    # Holds all of the Y data to plot later.\n",
    "    plotY = []\n",
    "    \n",
    "    # Holds all of the ATL03 objects to plot groundtracks later\n",
    "    atl03s = []\n",
    "    \n",
    "    # Holds the indices of the beams that successfully read\n",
    "    I = []\n",
    "    \n",
    "    # Check the satellite orientation so we know which beams are strong and weak.\n",
    "    # Listed from Beam 1 to Beam 6 in the tracks array\n",
    "    A = h5py.File(atl03path, 'r')\n",
    "    if list(A['orbit_info']['sc_orient'])[0] == 1:\n",
    "    \tstrong = ['gt1r', 'gt2r', 'gt3r']\n",
    "    \tweak = ['gt1l', 'gt2l', 'gt3l']\n",
    "    elif list(A['orbit_info']['sc_orient'])[0] == 0:\n",
    "        strong = ['gt3l', 'gt2l', 'gt1l']\n",
    "        weak = ['gt3r', 'gt2r', 'gt1r']\n",
    "    else:\n",
    "        print('Satellite in transition orientation.')\n",
    "        A.close()\n",
    "        return 0, 0, 0, 0, 0\n",
    "    tracks = [strong[0], weak[0], strong[1], weak[1], strong[2], weak[2]]\n",
    "    \n",
    "    # The only purpose of this is to keep the data organised later.\n",
    "    beam_names = [f\"Beam {i}\" for i in range(1,7)]\n",
    "        \n",
    "    # Very quick quality check; if any of the segments have zero return photons at all,\n",
    "    # the file is just skipped on assumptions that the data quality isn't good\n",
    "    if keep_flagged == None:\n",
    "        for gt in tracks:\n",
    "            try:\n",
    "                if 0 in A[gt]['geolocation']['ph_index_beg']:\n",
    "                    print('File ' + str(file_index) + ' has been skipped because some segments contain zero photon returns.')\n",
    "                    A.close()\n",
    "                    return 0, 0, 0, 0, 0\n",
    "                # This block will be executed if 0 is found in the list\n",
    "            except (KeyError, FileNotFoundError):\n",
    "            # Handle the exception (e.g., print a message or log the error)\n",
    "                continue\n",
    "\n",
    "    A.close()\n",
    "\n",
    "    #Keep indices of colors to plot regression lines later:\n",
    "    colors = []\n",
    "    \n",
    "    # Extracting date and time from the filename\n",
    "    title_date = parse_filename_datetime(atl03path)\n",
    "    \n",
    "    # Holds the maximum of the successfully read Ev values to use as y-intercept\n",
    "    # guesses in the regression\n",
    "    maxes = []\n",
    "\n",
    "    B = h5py.File(atl08path, 'r')\n",
    "    \n",
    "    # If the user wants to know the fraction of segments that have canopy photons,\n",
    "    # then we need an array to save it\n",
    "    if (canopy_frac != None) & (terrain_frac != None):\n",
    "        canopy_frac = []\n",
    "        terrain_frac = []\n",
    "    elif canopy_frac != None:\n",
    "        canopy_frac = []\n",
    "    elif terrain_frac != None:\n",
    "        terrain_frac = []\n",
    "    \n",
    "    # Now that we have assurances that the data is good quality,\n",
    "    # we loop through the ground tracks\n",
    "    for i, gt in enumerate(tracks):\n",
    "        \n",
    "        # If the object fails to be created, we put worthless information into\n",
    "        # plotX, plotY, and canopy_frac to save us looping effort later\n",
    "        try:\n",
    "            atl03 = ATL03(atl03path, atl08path, gt)\n",
    "        except (KeyError, ValueError, OSError) as e:\n",
    "            plotX.append([])\n",
    "            plotY.append([])\n",
    "            if canopy_frac != None:\n",
    "                canopy_frac.append(-1)\n",
    "            if terrain_frac != None:\n",
    "                terrain_frac.append(-1)\n",
    "            continue\n",
    "            \n",
    "        # The user specifies whether or not they want outliers to be present\n",
    "        # in the data, generally data points with zero canopy height or canopy photon returns\n",
    "        if zeros == None:\n",
    "            atl08 = ATL08(atl08path, gt)\n",
    "        \n",
    "        else:\n",
    "            atl08 = ATL08_with_zeros(atl08path, gt)\n",
    "\n",
    "        #subset atl08 dataframe to within the polygon of interest\n",
    "        polygon = make_box(coords, width,height)\n",
    "        gdf_points = gpd.GeoDataFrame(atl08.df, geometry=gpd.points_from_xy(atl08.df['lon'], atl08.df['lat']), crs='EPSG:4326')\n",
    "        atl08.df = gpd.sjoin(gdf_points, polygon, how='left', predicate='within').dropna().drop(['index_right'],axis=1)\n",
    "\n",
    "\n",
    "            \n",
    "        # Retrieve the canopy fraction (fraction of segments that contain any\n",
    "        # canopy photons) if the user wants it.\n",
    "        if canopy_frac != None:\n",
    "            canopy_frac.append(np.array(list(B[gt]['land_segments']['canopy']['subset_can_flag'])).flatten().mean())\n",
    "        if terrain_frac != None:\n",
    "            terrain_frac.append(np.array(list(B[gt]['land_segments']['terrain']['subset_te_flag'])).flatten().mean())\n",
    "\n",
    "        msw_flag = np.concatenate((msw_flag,B[gt]['land_segments']['msw_flag']))\n",
    "        night_flag = np.concatenate((night_flag,B[gt]['land_segments']['night_flag']))\n",
    "        asr = np.concatenate((asr,B[gt]['land_segments']['asr']))\n",
    "        \n",
    "        \n",
    "        # X and Y are data for the regression\n",
    "        X = atl08.df.Eg\n",
    "        Y = atl08.df.Ev\n",
    "        \n",
    "        if i % 2 == 0:\n",
    "            meanEgstrong.append(np.mean(X))\n",
    "            meanEvstrong.append(np.mean(Y))\n",
    "        else:\n",
    "            meanEgweak.append(np.mean(X))\n",
    "            meanEvweak.append(np.mean(Y))\n",
    "        \n",
    "        # Save it for plotting after the loop goes through all the groundtracks\n",
    "        plotX.append(X)\n",
    "        plotY.append(Y)\n",
    "        \n",
    "        # Save the ATL03 object\n",
    "        atl03s.append(atl03)\n",
    "        \n",
    "        # Save each individual data point from the ground track along with the Beam it belongs to.\n",
    "        for x, y in zip(X,Y):\n",
    "            dataset.append([x, y, beam_names[i]])\n",
    "            \n",
    "        if len(Y) == 0:\n",
    "            print(f'Beam {i + 1} in file {file_index} has been skipped because of no data.')\n",
    "            continue\n",
    "        \n",
    "        # We append the colour we need for the plotting later.\n",
    "        # Useful when the function is run many times to have many plots\n",
    "        # and we want the colours to be consistent\n",
    "        colors.append(i)\n",
    "        \n",
    "        # Save the initial y_intercept guess\n",
    "        maxes.append(y_init(Y))\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(dataset, columns=['Eg', 'Ev', 'gt'])\n",
    "\n",
    "    # Dummy encode the categorical variable\n",
    "    df_encoded = pd.get_dummies(df, columns=['gt'], prefix='', prefix_sep='')\n",
    "\n",
    "    if df_encoded.shape[0] == 0:\n",
    "        print(f'No beams have data in file {file_index}, cannot regress.')\n",
    "        return 0, 0, 0, 0, 0\n",
    "    # Retrieve optimal coefficients [slope, y_intercept_dataset_1, y_intercept_dataset_2, etc.]\n",
    "    coefs = odr(df_encoded, maxes = maxes, init = init, lb=lb, ub=ub, model = model, res = res, loss=loss, f_scale=f_scale)\n",
    "    \n",
    "    if len(colors) == 0:\n",
    "        graph_detail = 0\n",
    "        \n",
    "    if graph_detail == 3:\n",
    "        plot_parallel(atl03s = atl03s,\n",
    "                      coefs = coefs,\n",
    "                      colors = colors,\n",
    "                      title_date = title_date,\n",
    "                      X = plotX,\n",
    "                      Y = plotY,\n",
    "                      beam = beam,\n",
    "                      canopy_frac = canopy_frac,\n",
    "                      terrain_frac = terrain_frac,\n",
    "                      file_index = file_index,\n",
    "                      three = True)\n",
    "\n",
    "    # Activate this if you want the whole shebang\n",
    "    elif graph_detail == 2:\n",
    "        plot_parallel(atl03s = atl03s,\n",
    "                      coefs = coefs,\n",
    "                      colors = colors,\n",
    "                      title_date = title_date,\n",
    "                      X = plotX,\n",
    "                      Y = plotY,\n",
    "                      beam = beam,\n",
    "                      canopy_frac = canopy_frac,\n",
    "                      terrain_frac = terrain_frac,\n",
    "                      file_index = file_index)\n",
    "    \n",
    "    # Activate this if you don't want the groundtracks, just the plot\n",
    "    elif graph_detail == 1:\n",
    "        plot_graph(coefs = coefs,\n",
    "                   colors = colors,\n",
    "                   title_date = title_date,\n",
    "                   X = plotX,\n",
    "                   Y = plotY,\n",
    "                   beam = beam,\n",
    "                   file_index = file_index)\n",
    "    # Don't activate either of them if you don't want a plot\n",
    "    \n",
    "    means = [meanEgstrong, meanEgweak, meanEvstrong, meanEvweak]\n",
    "    \n",
    "    #Return the coefficients\n",
    "    return coefs, means, np.mean(msw_flag), np.mean(night_flag), np.mean(asr)\n",
    "\n",
    "\n",
    "def do_parallel(dirpath, files = None,f_scale = .1, loss = 'arctan', init = -1, lb = -100, ub = -1/100, model = parallel_model,\\\n",
    "    res = parallel_residuals, odr = parallel_odr, zeros=None, beam = None, y_init = np.max, graph_detail = 0, canopy_frac = None,\\\n",
    "    terrain_frac = None, keep_flagged=True): #keep_flagged default is None\n",
    "\n",
    "    data = []\n",
    "\n",
    "    all_ATL03, all_ATL08 = track_pairs(dirpath)\n",
    "    N = len(all_ATL03)\n",
    "    if files != None:\n",
    "        for j in files:\n",
    "            coefs, means, msw_flag, night_flag, asr= pvpg_parallel(all_ATL03[j],all_ATL08[j],file_index = j,f_scale=f_scale,\\\n",
    "                loss=loss,init=init,lb=lb,ub=ub,model=model,res=res,odr=odr,zeros=zeros,beam=beam,y_init=y_init,graph_detail=graph_detail,\\\n",
    "                canopy_frac=canopy_frac,terrain_frac=terrain_frac,keep_flagged=keep_flagged)\n",
    "            data.append([j,coefs,means,msw_flag,night_flag,asr])\n",
    "    else:\n",
    "        for j in range(N):\n",
    "            coefs, means, msw_flag, night_flag, asr= pvpg_parallel(all_ATL03[j],all_ATL08[j],file_index = j,f_scale=f_scale,\\\n",
    "                loss=loss,init=init,lb=lb,ub=ub,model=model,res=res,odr=odr,zeros=zeros,beam=beam,y_init=y_init,graph_detail=graph_detail,\\\n",
    "                canopy_frac=canopy_frac,terrain_frac=terrain_frac,keep_flagged=keep_flagged)\n",
    "            data.append([j,coefs,means,msw_flag,night_flag,asr])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7629e5b6-17f9-41e5-a716-2eb9aa4194db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           lat        lon         gh         ch   Ng  Nv        Eg        Ev  \\\n",
      "662  64.862770  26.114244  87.437057  16.171410   34  16  0.680000  0.460000   \n",
      "663  64.859200  26.113317  87.139656  19.543533   34  23  0.680000  0.580000   \n",
      "664  64.857414  26.112854  74.837563  16.295486  403  15  5.757143  0.271429   \n",
      "672  64.797623  26.097298  34.302547  22.325912   37  25  0.698113  0.547170   \n",
      "679  64.719101  26.076925  62.859028  27.417694   32  14  0.744186  0.441860   \n",
      "680  64.717316  26.076462  61.722076  24.536438  264  13  3.882353  0.235294   \n",
      "682  64.709282  26.074389  80.136368  17.503403   36  17  0.947368  0.473684   \n",
      "\n",
      "                      geometry  \n",
      "662  POINT (26.11424 64.86277)  \n",
      "663  POINT (26.11332 64.85920)  \n",
      "664  POINT (26.11285 64.85741)  \n",
      "672  POINT (26.09730 64.79762)  \n",
      "679  POINT (26.07693 64.71910)  \n",
      "680  POINT (26.07646 64.71732)  \n",
      "682  POINT (26.07439 64.70928)  \n",
      "\n",
      "            lat        lon         gh         ch   Ng   Nv        Eg  \\\n",
      "15    79.980629  34.308006  20.727026   4.229359  128   26  1.280000   \n",
      "21    79.975372  34.301437  21.286402   2.397675  145   25  1.380952   \n",
      "29    79.968369  34.292648  20.562325   1.687174  100   77  0.884956   \n",
      "43    79.956116  34.277336  21.811325   3.344362  133   21  1.330000   \n",
      "54    79.946487  34.265316  20.654047   2.874315  121   45  1.110092   \n",
      "...         ...        ...        ...        ...  ...  ...       ...   \n",
      "5685  59.502216  24.885614  37.016411  16.048580   50  133  0.450450   \n",
      "5686  59.501324  24.885431  37.564270  19.319729   73   79  0.722772   \n",
      "5687  59.500431  24.885250  38.295193  22.574192   68  102  0.618182   \n",
      "5688  59.499535  24.885069  39.789749  27.078712   39  128  0.371429   \n",
      "5689  59.498642  24.884890  40.326000  25.116531   59   81  0.595960   \n",
      "\n",
      "            Ev                   geometry  \n",
      "15    0.270000  POINT (34.30801 79.98063)  \n",
      "21    0.247619  POINT (34.30144 79.97537)  \n",
      "29    0.690265  POINT (34.29265 79.96837)  \n",
      "43    0.220000  POINT (34.27734 79.95612)  \n",
      "54    0.834862  POINT (34.26532 79.94649)  \n",
      "...        ...                        ...  \n",
      "5685  1.423423  POINT (24.88561 59.50222)  \n",
      "5686  0.851485  POINT (24.88543 59.50132)  \n",
      "5687  1.200000  POINT (24.88525 59.50043)  \n",
      "5688  1.571429  POINT (24.88507 59.49953)  \n",
      "5689  1.121212  POINT (24.88489 59.49864)  \n",
      "\n",
      "[3301 rows x 9 columns]\n",
      "\n",
      "                                            geometry\n",
      "0  POLYGON ((29.63415 64.36183, 29.63415 70.36183...\n"
     ]
    }
   ],
   "source": [
    "dirpath = '../data/sodankyla_full/'\n",
    "\n",
    "data = []\n",
    "\n",
    "all_ATL03, all_ATL08 = track_pairs(dirpath)\n",
    "N = len(all_ATL03)\n",
    "\n",
    "atl03 = ATL03(all_ATL03[0],all_ATL08[0],'gt1r')\n",
    "atl08 = ATL08(all_ATL08[0], 'gt1r')\n",
    "\n",
    "coords = (26.634154, 67.361833)\n",
    "\n",
    "gdf = make_box(coords, 3,3)\n",
    "\n",
    "# atl08.df['geometry'] = atl08.df.apply(lambda x: Point((float(x['lon']), float(x['lat']))), axis=1)\n",
    "gdf_points = gpd.GeoDataFrame(atl08.df, geometry=gpd.points_from_xy(atl08.df['lon'], atl08.df['lat']), crs='EPSG:4326')\n",
    "# gdf_points = gpd.GeoDataFrame(atl08.df, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "# Spatially join the two GeoDataFrames\n",
    "atl08.df = gpd.sjoin(gdf_points, gdf, how='left', predicate='within')\n",
    "\n",
    "# print(atl08.df.dropna().drop(['index_right'],axis=1))\n",
    "print(atl08.df.dropna().drop(['index_right'],axis=1))\n",
    "print()\n",
    "print(gdf_points)\n",
    "print()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "72ed1d1f-37d1-4de1-86b9-3faf5bd41f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, box as shapely_box\n",
    "import simplekml\n",
    "def make_box(coords, width=2, height=2):\n",
    "    w = width\n",
    "    h = height\n",
    "    polygon = gpd.GeoDataFrame(geometry=[box(coords[0]-w, coords[1]-h, coords[0]+w, coords[1]+h)], crs=\"EPSG:4326\")\n",
    "\n",
    "    return polygon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
