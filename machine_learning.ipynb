{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0056215f-b3c2-4009-8b93-78db7f2b566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.imports import *\n",
    "\n",
    "df = pd.read_pickle('five_sites_data_snow_cc.pkl')\n",
    "df = df[df['Confidence'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f608df3-81c9-49f3-9815-71c86c49cefc",
   "metadata": {},
   "source": [
    "# This first one is rudimentary because I think I can build it quickly. I want to make a second attempt further down using the segments in each 500m cell individually to do fractional snow cover, i.e. an algorithm that binary detects snow/non-snow per segment, and if 4/5 segments are snow-detected then we get 80% FSC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e908d21-33ef-4cbc-b681-0d279c48e384",
   "metadata": {},
   "source": [
    "#### Classification Accuracy and RMSE for MxD10A1F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "985efa53-186e-4105-8f72-326ade0d5ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.31574939008390074\n",
      "\n",
      "Classification FSC\n",
      "Optimal Threshold: 6.434343434343434\n",
      "Best F1-Score: 0.9846378931967813\n",
      "\n",
      "Classification JointSnow\n",
      "Optimal Thresholds: (6.434343434343434, 55.151515151515156)\n",
      "Best Macro-Averaged F1-Score: 0.6611897780614685\n"
     ]
    }
   ],
   "source": [
    "from scripts.imports import *\n",
    "\n",
    "df = pd.read_pickle('five_sites_data_snow_cc.pkl')\n",
    "df = df[df['Confidence'] == 1]\n",
    "\n",
    "X = df[['camera','meanEgstrong', 'meanEvstrong', 'msw', 'asr', 'night','MxD10A1F','FSC','JointSnow']]\n",
    "X = X[X['MxD10A1F'] <= 100].dropna().reset_index(drop=True)\n",
    "\n",
    "##############################\n",
    "\n",
    "rmse = np.sqrt(np.mean((X['MxD10A1F'] / 100 - X['FSC']) ** 2))\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "##############################\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Assuming X is your DataFrame\n",
    "\n",
    "# Initialize variables to store the best F1-score and corresponding threshold\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "# Loop through possible thresholds between the minimum and maximum values of X['MxD10A1F']\n",
    "thresholds = np.linspace(X['MxD10A1F'].min(), X['MxD10A1F'].max(), 100)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Apply threshold to classify X['MxD10A1F']\n",
    "    y_pred = np.where(X['MxD10A1F'] > threshold, 1, 0)\n",
    "    \n",
    "    # Compute the F1-score between the predicted labels and true labels (X['FSC'])\n",
    "    current_f1 = f1_score(X['FSC'], y_pred)\n",
    "    \n",
    "    # Check if the current F1-score is better than the best one found so far\n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print()\n",
    "print(\"Classification FSC\")\n",
    "print(f\"Optimal Threshold: {best_threshold}\")\n",
    "print(f\"Best F1-Score: {best_f1}\")\n",
    "\n",
    "##############################\n",
    "\n",
    "# Initialize variables to store the best F1-score and corresponding thresholds\n",
    "best_f1 = 0\n",
    "best_thresholds = (0, 0)\n",
    "\n",
    "# Define a function to classify based on two thresholds\n",
    "def classify_mxd10a1f(value, threshold1, threshold2):\n",
    "    if value <= threshold1:\n",
    "        return 0  # Class 0\n",
    "    elif threshold1 < value <= threshold2:\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 2  # Class 2\n",
    "\n",
    "# Loop through possible thresholds\n",
    "thresholds1 = np.linspace(X['MxD10A1F'].min(), X['MxD10A1F'].max(), 100)\n",
    "thresholds2 = np.linspace(X['MxD10A1F'].min(), X['MxD10A1F'].max(), 100)\n",
    "\n",
    "for threshold1 in thresholds1:\n",
    "    for threshold2 in thresholds2:\n",
    "        if threshold1 >= threshold2:\n",
    "            continue  # Ensure that threshold1 < threshold2\n",
    "        \n",
    "        # Apply the thresholds to classify X['MxD10A1F'] into 0, 1, or 2\n",
    "        y_pred = X['MxD10A1F'].apply(lambda x: classify_mxd10a1f(x, threshold1, threshold2))\n",
    "        \n",
    "        # Compute the macro-averaged F1 score between JointSnow and the predicted values\n",
    "        current_f1 = f1_score(X['JointSnow'], y_pred, average='macro')\n",
    "        \n",
    "        # Check if the current F1-score is better than the best one found so far\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_thresholds = (threshold1, threshold2)\n",
    "\n",
    "print()\n",
    "print(\"Classification JointSnow\")\n",
    "print(f\"Optimal Thresholds: {best_thresholds}\")\n",
    "print(f\"Best Macro-Averaged F1-Score: {best_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c3629-7d39-4b01-98fa-41354c830f5a",
   "metadata": {},
   "source": [
    "#### How many data points from each site?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6296029-ef1c-4d54-8ec4-2c556e3f57b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556 446 515 241 82\n"
     ]
    }
   ],
   "source": [
    "from scripts.imports import *\n",
    "\n",
    "df = pd.read_pickle('five_sites_data_snow_cc.pkl')\n",
    "df = df[df['Confidence'] == 1]\n",
    "\n",
    "X = df[['camera','meanEgstrong', 'meanEvstrong', 'msw', 'asr', 'night']]\n",
    "X = X.dropna()\n",
    "# y = df['FSC']\n",
    "\n",
    "print(X[X['camera']=='sodankyla_full'].shape[0],X[X['camera']=='delta_junction'].shape[0],X[X['camera']=='marcell_MN'].shape[0],X[X['camera']=='lacclair'].shape[0],X[X['camera']=='torgnon'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c9db6-9ba7-4b00-b7c3-041b9b59a263",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe776fb5-17e2-4177-87e4-e61c9b5ba5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Left-out group: delta_junction, RMSE: 0.3379415492106153\n",
      "Fold 2: Left-out group: marcell_MN, RMSE: 0.47158627934567215\n",
      "Fold 3: Left-out group: sodankyla_full, RMSE: 0.35563478728273373\n",
      "Mean Cross-Validation RMSE:  0.38838753861300707\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# Step 1: Splitting the data based on the 'camera' column\n",
    "train_sites = ['sodankyla_full', 'delta_junction', 'marcell_MN']\n",
    "test_sites = ['lacclair', 'torgnon']\n",
    "\n",
    "# Training set: data from 'sodankyla_full', 'delta_junction', and 'marcell_MN'\n",
    "train_df = df[df['camera'].isin(train_sites)]\n",
    "\n",
    "# Test set: data from 'lacclair' and 'torgnon' (We'll keep this aside for final evaluation)\n",
    "test_df = df[df['camera'].isin(test_sites)]\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = train_df[['meanEgstrong', 'meanEvstrong', 'msw', 'asr', 'night']]  # Add other relevant columns\n",
    "y_train = train_df['FSC']\n",
    "\n",
    "# Drop rows with NaN values in X_train and ensure y_train aligns with the filtered X_train\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]  # Align y_train with X_train\n",
    "\n",
    "# Dummy encode 'night' feature\n",
    "X_train = pd.get_dummies(X_train, columns=['night'], drop_first=True)\n",
    "\n",
    "# Extract the 'camera' column as the group identifier for cross-validation\n",
    "groups = train_df['camera'][X_train.index]  # Ensure 'groups' aligns with the filtered X_train\n",
    "\n",
    "# Step 2: Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Step 3: Perform bootstrapping and cross-validation\n",
    "n_bootstraps = 100  # Number of bootstraps\n",
    "cv_results = []\n",
    "left_out_groups = []  # To store the left-out group (site) for each fold\n",
    "\n",
    "for train_idx, test_idx in logo.split(X_train, y_train, groups):\n",
    "    # Get the training and validation data for this fold\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    # Get the left-out group (site) for this fold\n",
    "    left_out_group = groups.iloc[test_idx].unique()[0]  # Only one unique site is left out\n",
    "    left_out_groups.append(left_out_group)\n",
    "    \n",
    "    # Perform bootstrapping 100 times\n",
    "    fold_rmse_scores = []\n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sampling with replacement\n",
    "        X_bootstrap, y_bootstrap = resample(X_fold_train, y_fold_train, random_state=i)\n",
    "        \n",
    "        # Train the Linear Regression model on the bootstrap sample\n",
    "        lr_model.fit(X_bootstrap, y_bootstrap)\n",
    "        \n",
    "        # Validate the model on the validation fold\n",
    "        y_val_pred = lr_model.predict(X_fold_val)\n",
    "        \n",
    "        # Calculate RMSE and append to the fold results\n",
    "        rmse = np.sqrt(mean_squared_error(y_fold_val, y_val_pred))\n",
    "        fold_rmse_scores.append(rmse)\n",
    "    \n",
    "    # Store the average RMSE score for this fold\n",
    "    cv_results.append(np.mean(fold_rmse_scores))\n",
    "\n",
    "# Step 4: Print the cross-validation results along with the left-out groups\n",
    "for i, group in enumerate(left_out_groups):\n",
    "    print(f\"Fold {i+1}: Left-out group: {group}, RMSE: {cv_results[i]}\")\n",
    "print(\"Mean Cross-Validation RMSE: \", np.mean(cv_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc64c8a-4cfb-42de-b39d-058381f80f67",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "821c32bc-3272-4269-b588-eb0124391de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Left-out group: delta_junction, F1 Score: 0.8875110846775404\n",
      "Fold 2: Left-out group: marcell_MN, F1 Score: 0.768263651552506\n",
      "Fold 3: Left-out group: sodankyla_full, F1 Score: 0.8677306672951767\n",
      "Mean Cross-Validation F1 Score:  0.841168467841741\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# Step 1: Splitting the data based on the 'camera' column\n",
    "train_sites = ['sodankyla_full', 'delta_junction', 'marcell_MN']\n",
    "test_sites = ['lacclair', 'torgnon']\n",
    "\n",
    "# Training set: data from 'sodankyla_full', 'delta_junction', and 'marcell_MN'\n",
    "train_df = df[df['camera'].isin(train_sites)]\n",
    "\n",
    "# Test set: data from 'lacclair' and 'torgnon' (We'll keep this aside for final evaluation)\n",
    "test_df = df[df['camera'].isin(test_sites)]\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = train_df[['meanEgstrong', 'meanEvstrong', 'msw', 'asr', 'night']]  # Add other relevant columns\n",
    "y_train = train_df['FSC']\n",
    "\n",
    "# Drop rows with NaN values in X_train and ensure y_train aligns with the filtered X_train\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]  # Align y_train with X_train\n",
    "\n",
    "# Dummy encode 'night' feature\n",
    "X_train = pd.get_dummies(X_train, columns=['night'], drop_first=True)\n",
    "\n",
    "# Extract the 'camera' column as the group identifier for cross-validation\n",
    "groups = train_df['camera'][X_train.index]  # Ensure 'groups' aligns with the filtered X_train\n",
    "\n",
    "# Step 2: Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Step 3: Perform bootstrapping and cross-validation\n",
    "n_bootstraps = 100  # Number of bootstraps\n",
    "cv_results = []\n",
    "left_out_groups = []  # To store the left-out group (site) for each fold\n",
    "\n",
    "for train_idx, test_idx in logo.split(X_train, y_train, groups):\n",
    "    # Get the training and validation data for this fold\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    # Get the left-out group (site) for this fold\n",
    "    left_out_group = groups.iloc[test_idx].unique()[0]  # Only one unique site is left out\n",
    "    left_out_groups.append(left_out_group)\n",
    "    \n",
    "    # Perform bootstrapping 100 times\n",
    "    fold_f1_scores = []\n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sampling with replacement\n",
    "        X_bootstrap, y_bootstrap = resample(X_fold_train, y_fold_train, random_state=i)\n",
    "        \n",
    "        # Train the Logistic Regression model on the bootstrap sample\n",
    "        lr_model.fit(X_bootstrap, y_bootstrap)\n",
    "        \n",
    "        # Validate the model on the validation fold\n",
    "        y_val_pred = lr_model.predict(X_fold_val)\n",
    "        \n",
    "        # Calculate F1 score and append to the fold results\n",
    "        f1 = f1_score(y_fold_val, y_val_pred)\n",
    "        fold_f1_scores.append(f1)\n",
    "    \n",
    "    # Store the average F1 score for this fold\n",
    "    cv_results.append(np.mean(fold_f1_scores))\n",
    "\n",
    "# Step 4: Print the cross-validation results along with the left-out groups\n",
    "for i, group in enumerate(left_out_groups):\n",
    "    print(f\"Fold {i+1}: Left-out group: {group}, F1 Score: {cv_results[i]}\")\n",
    "print(\"Mean Cross-Validation F1 Score: \", np.mean(cv_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50546ec2-0045-4a47-902b-b21294db3d0d",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a640ccdf-e84d-4300-8c9f-a63b1ef714d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Left-out group: delta_junction, F1 Score: 0.792529702974205\n",
      "Fold 2: Left-out group: marcell_MN, F1 Score: 0.6875191064407464\n",
      "Fold 3: Left-out group: sodankyla_full, F1 Score: 0.863481287548975\n",
      "Mean Cross-Validation F1 Score:  0.7811766989879755\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# Step 1: Splitting the data based on the 'camera' column\n",
    "train_sites = ['sodankyla_full', 'delta_junction', 'marcell_MN']\n",
    "test_sites = ['lacclair', 'torgnon']\n",
    "\n",
    "# Training set: data from 'sodankyla_full', 'delta_junction', and 'marcell_MN'\n",
    "train_df = df[df['camera'].isin(train_sites)]\n",
    "\n",
    "# Test set: data from 'lacclair' and 'torgnon' (We'll keep this aside for final evaluation)\n",
    "test_df = df[df['camera'].isin(test_sites)]\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = train_df[['meanEgstrong', 'meanEvstrong', 'msw', 'asr', 'night']]  # Add other relevant columns\n",
    "y_train = train_df['FSC']\n",
    "\n",
    "# Drop rows with NaN values in X_train and ensure y_train aligns with the filtered X_train\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]  # Align y_train with X_train\n",
    "\n",
    "# Dummy encode 'night' feature\n",
    "X_train = pd.get_dummies(X_train, columns=['night'], drop_first=True)\n",
    "\n",
    "# Extract the 'camera' column as the group identifier for cross-validation\n",
    "groups = train_df['camera'][X_train.index]  # Ensure 'groups' aligns with the filtered X_train\n",
    "\n",
    "# Step 2: Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Step 3: Perform bootstrapping and cross-validation\n",
    "n_bootstraps = 100  # Number of bootstraps\n",
    "cv_results = []\n",
    "left_out_groups = []\n",
    "\n",
    "for train_idx, test_idx in logo.split(X_train, y_train, groups):\n",
    "    # Get the training and validation data for this fold\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Get the left-out group (site) for this fold\n",
    "    left_out_group = groups.iloc[test_idx].unique()[0]  # Only one unique site is left out\n",
    "    left_out_groups.append(left_out_group)\n",
    "    \n",
    "    # Perform bootstrapping 100 times\n",
    "    fold_f1_scores = []\n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sampling with replacement\n",
    "        X_bootstrap, y_bootstrap = resample(X_fold_train, y_fold_train, random_state=i)\n",
    "        \n",
    "        # Train the decision tree classifier on the bootstrap sample\n",
    "        dt_classifier.fit(X_bootstrap, y_bootstrap)\n",
    "        \n",
    "        # Validate the model on the validation fold\n",
    "        y_val_pred = dt_classifier.predict(X_fold_val)\n",
    "        \n",
    "        # Calculate the F1 score and append to the fold results\n",
    "        f1 = f1_score(y_fold_val, y_val_pred)\n",
    "        fold_f1_scores.append(f1)\n",
    "    \n",
    "    # Store the average F1 score for this fold\n",
    "    cv_results.append(np.mean(fold_f1_scores))\n",
    "\n",
    "# Step 4: Print the cross-validation results along with the left-out groups\n",
    "for i, group in enumerate(left_out_groups):\n",
    "    print(f\"Fold {i+1}: Left-out group: {group}, F1 Score: {cv_results[i]}\")\n",
    "print(\"Mean Cross-Validation F1 Score: \", np.mean(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde8061-6799-467d-ae85-f119932bbd98",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d22a51-9538-40bd-ad02-3115e8fc64c1",
   "metadata": {},
   "source": [
    "Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95469385-8344-43d4-8123-21e0d0806420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Left-out group: delta_junction, F1 Score: 0.8456644970202808\n",
      "Fold 2: Left-out group: marcell_MN, F1 Score: 0.7495452431687483\n",
      "Fold 3: Left-out group: sodankyla_full, F1 Score: 0.9007255720762799\n",
      "Mean Cross-Validation F1 Score:  0.8319784374217697\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# Step 1: Splitting the data based on the 'camera' column\n",
    "train_sites = ['sodankyla_full', 'delta_junction', 'marcell_MN']\n",
    "test_sites = ['lacclair', 'torgnon']\n",
    "\n",
    "# Training set: data from 'sodankyla_full', 'delta_junction', and 'marcell_MN'\n",
    "train_df = df[df['camera'].isin(train_sites)]\n",
    "\n",
    "# Test set: data from 'lacclair' and 'torgnon' (We'll keep this aside for final evaluation)\n",
    "test_df = df[df['camera'].isin(test_sites)]\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = train_df[['meanEgstrong', 'meanEvstrong', 'msw', 'asr', 'night']]  # Add other relevant columns\n",
    "y_train = train_df['FSC']\n",
    "\n",
    "# Drop rows with NaN values in X_train and ensure y_train aligns with the filtered X_train\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]  # Align y_train with X_train\n",
    "\n",
    "# Dummy encode 'night' feature\n",
    "X_train = pd.get_dummies(X_train, columns=['night'], drop_first=True)\n",
    "\n",
    "# Extract the 'camera' column as the group identifier for cross-validation\n",
    "groups = train_df['camera'][X_train.index]  # Ensure 'groups' aligns with the filtered X_train\n",
    "\n",
    "# Step 2: Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Step 3: Perform bootstrapping and cross-validation\n",
    "n_bootstraps = 100  # Number of bootstraps\n",
    "cv_results = []\n",
    "left_out_groups = []\n",
    "\n",
    "for train_idx, test_idx in logo.split(X_train, y_train, groups):\n",
    "    # Get the training and validation data for this fold\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Get the left-out group (site) for this fold\n",
    "    left_out_group = groups.iloc[test_idx].unique()[0]  # Only one unique site is left out\n",
    "    left_out_groups.append(left_out_group)\n",
    "    \n",
    "    # Perform bootstrapping 100 times\n",
    "    fold_f1_scores = []\n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sampling with replacement\n",
    "        X_bootstrap, y_bootstrap = resample(X_fold_train, y_fold_train, random_state=i)\n",
    "        \n",
    "        # Train the Random Forest classifier on the bootstrap sample\n",
    "        rf_classifier.fit(X_bootstrap, y_bootstrap)\n",
    "        \n",
    "        # Validate the model on the validation fold\n",
    "        y_val_pred = rf_classifier.predict(X_fold_val)\n",
    "        \n",
    "        # Calculate the F1 score and append to the fold results\n",
    "        f1 = f1_score(y_fold_val, y_val_pred)\n",
    "        fold_f1_scores.append(f1)\n",
    "    \n",
    "    # Store the average F1 score for this fold\n",
    "    cv_results.append(np.mean(fold_f1_scores))\n",
    "\n",
    "# Step 4: Print the cross-validation results along with the left-out groups\n",
    "for i, group in enumerate(left_out_groups):\n",
    "    print(f\"Fold {i+1}: Left-out group: {group}, F1 Score: {cv_results[i]}\")\n",
    "print(\"Mean Cross-Validation F1 Score: \", np.mean(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e43c16-4cee-424e-8fdb-29e20c1ca600",
   "metadata": {},
   "source": [
    "Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb743a6f-dcb5-4889-addc-b5920a06086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Left-out group: delta_junction, RMSE: 0.3930058156271325\n",
      "Fold 2: Left-out group: marcell_MN, RMSE: 0.4253265189429128\n",
      "Fold 3: Left-out group: sodankyla_full, RMSE: 0.3024553661194076\n",
      "Mean Cross-Validation RMSE:  0.37359590022981765\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# Step 1: Splitting the data based on the 'camera' column\n",
    "train_sites = ['sodankyla_full', 'delta_junction', 'marcell_MN']\n",
    "test_sites = ['lacclair', 'torgnon']\n",
    "\n",
    "# Training set: data from 'sodankyla_full', 'delta_junction', and 'marcell_MN'\n",
    "train_df = df[df['camera'].isin(train_sites)]\n",
    "\n",
    "# Test set: data from 'lacclair' and 'torgnon' (We'll keep this aside for final evaluation)\n",
    "test_df = df[df['camera'].isin(test_sites)]\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = train_df[['meanEgstrong', 'meanEvstrong', 'msw', 'asr', 'night']]  # Add other relevant columns\n",
    "y_train = train_df['FSC']\n",
    "\n",
    "# Drop rows with NaN values in X_train and ensure y_train aligns with the filtered X_train\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]  # Align y_train with X_train\n",
    "\n",
    "# Dummy encode 'night' feature\n",
    "X_train = pd.get_dummies(X_train, columns=['night'], drop_first=True)\n",
    "\n",
    "# Extract the 'camera' column as the group identifier for cross-validation\n",
    "groups = train_df['camera'][X_train.index]  # Ensure 'groups' aligns with the filtered X_train\n",
    "\n",
    "# Step 2: Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Step 3: Perform bootstrapping and cross-validation\n",
    "n_bootstraps = 100  # Number of bootstraps\n",
    "cv_results = []\n",
    "left_out_groups = []  # To store the left-out group (site) for each fold\n",
    "\n",
    "for train_idx, test_idx in logo.split(X_train, y_train, groups):\n",
    "    # Get the training and validation data for this fold\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    # Get the left-out group (site) for this fold\n",
    "    left_out_group = groups.iloc[test_idx].unique()[0]  # Only one unique site is left out\n",
    "    left_out_groups.append(left_out_group)\n",
    "    \n",
    "    # Perform bootstrapping 100 times\n",
    "    fold_rmse_scores = []\n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sampling with replacement\n",
    "        X_bootstrap, y_bootstrap = resample(X_fold_train, y_fold_train, random_state=i)\n",
    "        \n",
    "        # Train the Random Forest Regressor on the bootstrap sample\n",
    "        rf_regressor.fit(X_bootstrap, y_bootstrap)\n",
    "        \n",
    "        # Validate the model on the validation fold\n",
    "        y_val_pred = rf_regressor.predict(X_fold_val)\n",
    "        \n",
    "        # Calculate RMSE and append to the fold results\n",
    "        rmse = np.sqrt(mean_squared_error(y_fold_val, y_val_pred))\n",
    "        fold_rmse_scores.append(rmse)\n",
    "    \n",
    "    # Store the average RMSE score for this fold\n",
    "    cv_results.append(np.mean(fold_rmse_scores))\n",
    "\n",
    "# Step 4: Print the cross-validation results along with the left-out groups\n",
    "for i, group in enumerate(left_out_groups):\n",
    "    print(f\"Fold {i+1}: Left-out group: {group}, RMSE: {cv_results[i]}\")\n",
    "print(\"Mean Cross-Validation RMSE: \", np.mean(cv_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2618b07-0113-4329-96e5-00458f79a39e",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564cf1d5-10e7-4cdc-abb7-45358682e8ea",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a33618a6-1b74-414a-94c5-fce7a74ae4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Left-out group: delta_junction, F1 Score: 0.763728133131482\n",
      "Fold 2: Left-out group: marcell_MN, F1 Score: 0.7164310687684331\n",
      "Fold 3: Left-out group: sodankyla_full, F1 Score: 0.8818990618535529\n",
      "Mean Cross-Validation F1 Score:  0.7873527545844894\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "\n",
    "# Step 1: Splitting the data based on the 'camera' column\n",
    "train_sites = ['sodankyla_full', 'delta_junction', 'marcell_MN']\n",
    "test_sites = ['lacclair', 'torgnon']\n",
    "\n",
    "# Training set: data from 'sodankyla_full', 'delta_junction', and 'marcell_MN'\n",
    "train_df = df[df['camera'].isin(train_sites)]\n",
    "\n",
    "# Test set: data from 'lacclair' and 'torgnon' (We'll keep this aside for final evaluation)\n",
    "test_df = df[df['camera'].isin(test_sites)]\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = train_df[['meanEgstrong', 'meanEvstrong', 'msw', 'asr', 'night']]  # Add other relevant columns\n",
    "y_train = train_df['FSC']\n",
    "\n",
    "# Drop rows with NaN values in X_train and ensure y_train aligns with the filtered X_train\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]  # Align y_train with X_train\n",
    "\n",
    "# Dummy encode 'night' feature\n",
    "X_train = pd.get_dummies(X_train, columns=['night'], drop_first=True)\n",
    "\n",
    "# Extract the 'camera' column as the group identifier for cross-validation\n",
    "groups = train_df['camera'][X_train.index]  # Ensure 'groups' aligns with the filtered X_train\n",
    "\n",
    "# Step 2: Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],  # Kernel options: linear and radial basis function (RBF)\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf' kernel\n",
    "}\n",
    "\n",
    "# Step 3: Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize SVC model\n",
    "svc_model = SVC()\n",
    "\n",
    "# Step 4: Perform bootstrapping and cross-validation\n",
    "n_bootstraps = 100  # Number of bootstraps\n",
    "cv_results = []\n",
    "left_out_groups = []  # To store the left-out group (site) for each fold\n",
    "\n",
    "for train_idx, test_idx in logo.split(X_train, y_train, groups):\n",
    "    # Get the training and validation data for this fold\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    # Get the left-out group (site) for this fold\n",
    "    left_out_group = groups.iloc[test_idx].unique()[0]  # Only one unique site is left out\n",
    "    left_out_groups.append(left_out_group)\n",
    "    \n",
    "    # Perform GridSearchCV with bootstrapping\n",
    "    fold_f1_scores = []\n",
    "    \n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sampling with replacement\n",
    "        X_bootstrap, y_bootstrap = resample(X_fold_train, y_fold_train, random_state=i)\n",
    "        \n",
    "        # GridSearchCV for SVC\n",
    "        svc_search = GridSearchCV(svc_model, param_grid, cv=3, scoring='f1')\n",
    "        svc_search.fit(X_bootstrap, y_bootstrap)\n",
    "        best_svc = svc_search.best_estimator_\n",
    "        \n",
    "        # Predict and evaluate SVC on validation set\n",
    "        y_val_pred = best_svc.predict(X_fold_val)\n",
    "        f1 = f1_score(y_fold_val, y_val_pred)\n",
    "        fold_f1_scores.append(f1)\n",
    "    \n",
    "    # Store the average F1 score for this fold\n",
    "    cv_results.append(np.mean(fold_f1_scores))\n",
    "\n",
    "# Step 5: Print the cross-validation results along with the left-out groups\n",
    "for i, group in enumerate(left_out_groups):\n",
    "    print(f\"Fold {i+1}: Left-out group: {group}, F1 Score: {cv_results[i]}\")\n",
    "print(\"Mean Cross-Validation F1 Score: \", np.mean(cv_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2af0dc-fb3c-43b8-989b-883c3513464d",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5448c-edb6-473c-81d3-088a4eb6fac8",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094801e6-30b6-4700-b870-ca71f53414d8",
   "metadata": {},
   "source": [
    "Classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77bca6d-e84b-42c5-9aef-1d643a4465c5",
   "metadata": {},
   "source": [
    "Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded2fcc9-d743-4ad1-bffa-e5697de84acf",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9099b57-2351-4c92-a0ac-16f8222bdb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLURM Forth HPC 8 CPUs",
   "language": "",
   "name": "rik_slurm_forthhpc_8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
