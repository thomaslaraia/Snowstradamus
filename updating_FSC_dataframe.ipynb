{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c379a414",
   "metadata": {},
   "source": [
    "# Updating FSC Dataframe to search specifically for matching dates instead of file numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712ad491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 28 15:42:34 2024\n",
    "\n",
    "@author: s1803229\n",
    "\"\"\"\n",
    "\n",
    "from scripts.imports import os, glob, pdb, np, h5py, pd, xr, gpd, Proj, Transformer, CRS, \\\n",
    "                        plt, cmap, cmap2, Model, Data, ODR, datetime, rasterio, show, \\\n",
    "                        ccrs, cfeature\n",
    "import seaborn as sns\n",
    "from scripts.classes_fixed import *\n",
    "from scripts.track_pairs import *\n",
    "from scripts.show_tracks import *\n",
    "from scripts.parallel import pvpg_parallel\n",
    "\n",
    "# Function to compute mean without the warning\n",
    "def safe_nanmean(slice):\n",
    "    if len(slice) == 0 or np.isnan(slice).all():\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.nanmean(slice)\n",
    "\n",
    "def parse_filename_datetime(filename):\n",
    "    # Extracting only the filename from the full path\n",
    "    filename_only = filename.split('/')[-1]\n",
    "    \n",
    "    # Finding the index of the first appearance of 'ATL03_' or 'ATL08_'\n",
    "    atl03_index = filename_only.find('ATL03_')\n",
    "    atl08_index = filename_only.find('ATL08_')\n",
    "    \n",
    "    # Determining the split index based on which string appears first or if neither is found\n",
    "    split_index = min(filter(lambda x: x >= 0, [atl03_index, atl08_index]))\n",
    "\n",
    "    # Extracting yyyymmddhhmmss part\n",
    "    date_str = filename_only[split_index + 6:split_index + 20]\n",
    "    datetime_obj = datetime.strptime(date_str, '%Y%m%d%H%M%S')\n",
    "    \n",
    "    return datetime_obj\n",
    "\n",
    "def datetime_to_date(datetime_obj):\n",
    "    return datetime_obj.strftime('%d/%m/%Y')\n",
    "    \n",
    "def FSC_dataframe(dirpath, csv_path):\n",
    "    all_ATL03, all_ATL08 = track_pairs(dirpath)\n",
    "    N = len(all_ATL03)\n",
    "\n",
    "    foldername = dirpath.split('/')[-2]\n",
    "    \n",
    "    df = pd.read_csv(csv_path).drop('Image', axis=1).dropna()\n",
    "    \n",
    "    pvpg = []\n",
    "    mean_Eg_strong = []\n",
    "    mean_Eg_weak = []\n",
    "    mean_Ev_strong = []\n",
    "    mean_Ev_weak = []\n",
    "    msw_flags = []\n",
    "    night_flags = []\n",
    "    asrs = []\n",
    "    \n",
    "    for i, (atl03_filepath, atl08_filepath) in enumerate(zip(all_ATL03, all_ATL08)):\n",
    "        filedate = datetime_to_date(parse_filename_datetime(atl03_filepath))\n",
    "        if (filedate in df['Date'].values) and (#######################################################################\n",
    "        coefs,means,msw_flag,night_flag,asr = pvpg_parallel(all_ATL03[int(i)], all_ATL08[int(i)], file_index = int(i),loss='arctan')\n",
    "        pvpg.append(-coefs[0])\n",
    "        mean_Eg_strong.append(safe_nanmean(means[0]))\n",
    "        mean_Eg_weak.append(safe_nanmean(means[1]))\n",
    "        mean_Ev_strong.append(safe_nanmean(means[2]))\n",
    "        mean_Ev_weak.append(safe_nanmean(means[3]))\n",
    "        msw_flags.append(msw_flag)\n",
    "        night_flags.append(night_flag)\n",
    "        asrs.append(asr)\n",
    "    \n",
    "    df['pvpg'] = pvpg\n",
    "    df['mean_Eg_strong'] = mean_Eg_strong\n",
    "    df['mean_Eg_weak'] = mean_Eg_weak\n",
    "    df['mean_Ev_strong'] = mean_Ev_strong\n",
    "    df['mean_Ev_weak'] = mean_Ev_weak\n",
    "    df['msw_flag'] = msw_flags\n",
    "    df['night_flag'] = night_flags\n",
    "    df['asr'] = asrs\n",
    "    \n",
    "    #make categorical column\n",
    "    df['Joint Snow'] = df['Joint Snow'].astype('category')\n",
    "    df['FSC'] = df['FSC'].astype('category')\n",
    "    df['Tree Snow'] = df['Tree Snow'].astype('category')\n",
    "    \n",
    "    df_pure = df.drop(['Camera','Date'], axis=1)\n",
    "    \n",
    "    return df, df_pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ea8dff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/12/2018\n",
      "0\n",
      "12/01/2019\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "dirpath = '../data/sodankyla_full/'\n",
    "csv_path = 'snow_cam_details.csv'\n",
    "\n",
    "all_ATL03, all_ATL08 = track_pairs(dirpath)\n",
    "N = len(all_ATL03)\n",
    "\n",
    "df = pd.read_csv(csv_path).dropna().drop('Image', axis=1)\n",
    "\n",
    "for i in range(3,5):\n",
    "    A = datetime_to_date(parse_filename_datetime(all_ATL08[i]))\n",
    "    print(A)\n",
    "    if A in df['Date'].values:\n",
    "        print(1)\n",
    "        \n",
    "    else:\n",
    "        print(0)\n",
    "\n",
    "# dirpath.split('/')[-2]\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919e1cd9-06fd-43bf-9abc-30ab24243562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 4\n",
      "1 2 5\n",
      "2 3 6\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(zip([1,2,3],[4,5,6])):\n",
    "    print(i, x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
